{"meta":{"title":"Mino","subtitle":"Mino's personal blog","description":"Mino's personal blog","author":"Mino","url":"https://codermino.github.io","root":"/"},"posts":[{"tags":[{"name":"mysql知识点总结和应用2","slug":"mysql知识点总结和应用2","permalink":"https://codermino.github.io/tags/mysql%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%E5%92%8C%E5%BA%94%E7%94%A82/"}],"title":"mysql知识点总结和应用2","date":"2020/08/14","text":"视图视图概述视图（View）是一种虚拟存在的表。视图并不在数据库中实际存在，行和列数据来自定义视图的查询中使用的表，并且是在使用视图时动态生成的。通俗的讲，视图就是一条SELECT语句执行后返回的结果集。所以我们在创建视图的时候，主要的工作就落在创建这条SQL查询语句上。 视图相对于普通的表的优势主要包括以下几项。 简单：使用视图的用户完全不需要关心后面对应的表的结构、关联条件和筛选条件，对用户来说已经是过滤好的复合条件的结果集。 安全：使用视图的用户只能访问他们被允许查询的结果集，对表的权限管理并不能限制到某个行某个列，但是通过视图就可以简单的实现。 数据独立：一旦视图的结构确定了，可以屏蔽表结构变化对用户的影响，源表增加列对视图没有影响；源表修改列名，则可以通过修改视图来解决，不会造成对访问者的影响。 创建或者修改视图创建CREATE [OR REPLACE] [ALGORITHM = {UNDEFINED | MERGE | TEMPTABLE}] VIEW view_name [(column_list)] AS select_statement [WITH [CASCADED | LOCAL] CHECK OPTION] 修改ALTER [ALGORITHM = {UNDEFINED | MERGE | TEMPTABLE}] VIEW view_name [(column_list)] AS select_statement [WITH [CASCADED | LOCAL] CHECK OPTION]选项 : WITH [CASCADED | LOCAL] CHECK OPTION 决定了是否允许更新数据使记录不再满足视图的条件。 LOCAL ： 只要满足本视图的条件就可以更新。 CASCADED ： 必须满足所有针对该视图的所有视图的条件才可以更新。 默认值.(级联)示例 , 创建city_country_view视图 , 执行如下SQL : create or replace view city_country_view as select t.*,c.country_name from country c , city t where c.country_id = t.country_id; 删除视图DROP VIEW [IF EXISTS] view_name [, view_name] …[RESTRICT | CASCADE]示例 , 删除视图city_country_view : DROP VIEW city_country_view ;","permalink":"https://codermino.github.io/2020/08/14/mysql%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%E5%92%8C%E5%BA%94%E7%94%A82/","photos":[]},{"tags":[{"name":"mysql知识点总结和应用1","slug":"mysql知识点总结和应用1","permalink":"https://codermino.github.io/tags/mysql%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%E5%92%8C%E5%BA%94%E7%94%A81/"}],"title":"mysql知识点总结和应用1","date":"2020/08/14","text":"索引索引概述MySQL官方对索引的定义为：索引（index）是帮助MySQL高效获取数据的数据结构（有序）。在数据之外，数据库系统还维护者满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法，这种数据结构就是索引。如下面的==示意图==所示 : 左边是数据表，一共有两列七条记录，最左边的是数据记录的物理地址（注意逻辑上相邻的记录在磁盘上也并不是一定物理相邻的）。为了加快Col2的查找，可以维护一个右边所示的二叉查找树，每个节点分别包含索引键值和一个指向对应数据记录物理地址的指针，这样就可以运用二叉查找快速获取到相应数据。 一般来说索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储在磁盘上。索引是数据库中用来提高性能的最常用的工具。 索引优势劣势优势 1） 类似于书籍的目录索引，提高数据检索的效率，降低数据库的IO成本。 2） 通过索引列对数据进行排序，降低数据排序的成本，降低CPU的消耗。 劣势 1） 实际上索引也是一张表，该表中保存了主键与索引字段，并指向实体类的记录，所以索引列也是要占用空间的。 2） 虽然索引大大提高了查询效率，同时却也降低更新表的速度，如对表进行INSERT、UPDATE、DELETE。 因为更新表时，MySQL 不仅要保存数据，还要保存一下索引文件每次更新添加了索引列的字段， 都会调整因为更新所带来的键值变化后的索引信息。 索引结构索引是在MySQL的存储引擎层中实现的，而不是在服务器层实现的。所以每种存储引擎的索引都不一定完全相同，也不是所有的存储引擎都支持所有的索引类型的。MySQL目前提供了以下4种索引： BTREE 索引 ： 最常见的索引类型，大部分索引都支持 B 树索引。 HASH 索引：只有Memory引擎支持 ， 使用场景简单 。 R-tree 索引（空间索引）：空间索引是MyISAM引擎的一个特殊索引类型，主要用于地理空间数据类型，通常使用较少，不做特别介绍。 Full-text （全文索引） ：全文索引也是MyISAM的一个特殊索引类型，主要用于全文索引，InnoDB从Mysql5.6版本开始支持全文索引。 索引分类1） 单值索引 ：即一个索引只包含单个列，一个表可以有多个单列索引 2） 唯一索引 ：索引列的值必须唯一，但允许有空值 3） 复合索引 ：即一个索引包含多个列 索引语法创建索引CREATE [UNIQUE|FULLTEXT|SPATIAL] INDEX index_name[USING index_type]ON tbl_name(index_col_name,…) index_col_name : column_name[(length)][ASC | DESC]eq:create index idx_city_name on city(city_name); 查看索引show index from table_name[\\G]; 删除索引DROP INDEX index_name ON tbl_name; ALTER命令1). alter table tb_name add primary key(column_list); 该语句添加一个主键，这意味着索引值必须是唯一的，且不能为NULL2). alter table tb_name add unique index_name(column_list); 这条语句创建索引的值必须是唯一的（除了NULL外，NULL可能会出现多次）3). alter table tb_name add index index_name(column_list); 添加普通索引， 索引值可以出现多次。4). alter table tb_name add fulltext index_name(column_list); 该语句指定了索引为FULLTEXT， 用于全文索引索引设计原则索引的设计可以遵循一些已有的原则，创建索引的时候请尽量考虑符合这些原则，便于提升索引的使用效率，更高效的使用索引。 对查询频次较高，且数据量比较大的表建立索引。 索引字段的选择，最佳候选列应当从where子句的条件中提取，如果where子句中的组合比较多，那么应当挑选最常用、过滤效果最好的列的组合。 使用唯一索引，区分度越高，使用索引的效率越高。 索引可以有效的提升查询数据的效率，但索引数量不是多多益善，索引越多，维护索引的代价自然也就水涨船高。 对于插入、更新、删除等DML操作比较频繁的表来说，索引过多，会引入相当高的维护代价，降低DML操作的效率，增加相应操作的时间消耗。 另外索引过多的话，MySQL也会犯选择困难病，虽然最终仍然会找到一个可用的索引，但无疑提高了选择的代价。 使用短索引，索引创建之后也是使用硬盘来存储的，因此提升索引访问的I/O效率，也可以提升总体的访问效率。假如构成索引的字段总长度比较短， 那么在给定大小的存储块内可以存储更多的索引值，相应的可以有效的提升MySQL访问索引的I/O效率。 利用最左前缀，N个列组合而成的组合索引，那么相当于是创建了N个索引，如果查询时where子句中使用了组成该索引的前几个字段， 那么这条查询SQL可以利用组合索引来提升查询效率。 创建复合索引: CREATE INDEX idx_name_email_status ON tb_seller(NAME,email,STATUS); 就相当于 对name 创建索引 ; 对name , email 创建了索引 ; 对name , email, status 创建了索引 ;","permalink":"https://codermino.github.io/2020/08/14/mysql%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%E5%92%8C%E5%BA%94%E7%94%A81/","photos":[]},{"tags":[{"name":"找回密码功能流程","slug":"找回密码功能流程","permalink":"https://codermino.github.io/tags/%E6%89%BE%E5%9B%9E%E5%AF%86%E7%A0%81%E5%8A%9F%E8%83%BD%E6%B5%81%E7%A8%8B/"}],"title":"找回密码功能流程","date":"2020/08/14","text":"找回密码流程 1、注册时要求每个用户使用唯一的邮箱，注册后向用户的邮箱发一封邮件 2、找回密码时要求用户填写邮箱地址，提示用户如果不记得地址请在邮箱中搜索 3、找回密码功能限制每帐号每天只能使用三次(只能发三次邮件), 使用缓存来完成这个计数 4、找回密码时向缓存中写入一个随机的字符串作为 Token, 有效期为一天，向用户的邮箱发送包含 Token 的链接 5、用户从链接点回来先验证 Token 的有效性，然后提示填写新密码，然后将新密码和 Token 一起提交给后端完成修改密码的操作 6、删除掉 Token 的缓存","permalink":"https://codermino.github.io/2020/08/14/%E6%89%BE%E5%9B%9E%E5%AF%86%E7%A0%81%E5%8A%9F%E8%83%BD%E6%B5%81%E7%A8%8B/","photos":[]},{"tags":[{"name":"vuex页面刷新数据丢失问题","slug":"vuex页面刷新数据丢失问题","permalink":"https://codermino.github.io/tags/vuex%E9%A1%B5%E9%9D%A2%E5%88%B7%E6%96%B0%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E9%97%AE%E9%A2%98/"}],"title":"vuex页面刷新数据丢失问题","date":"2020/08/14","text":"vuex 数据在页面刷新后数据丢失问题解决方法：在APP.vue文件的created生命周期中加入以下代码： if(localStorage.eleToken)&#123; // 1.使用jwt_decode解码存储的token信息 const decoded = jwt_decode(localStorage.eleToken); console.log(decoded); //调用对应的函数，进行用户信息的存储 this.$store.dispatch(\"setAuthenticated\",isEmpty(localStorage.eleToken)); this.$store.dispatch(\"setUser\",decoded); &#125; 对应的vuex中的mutations和actions const mutations=&#123; set_authenticated(state,isAuthenticated)&#123; if(isAuthenticated)&#123; state.isAuthenticated=isAuthenticated; &#125;else&#123; state.isAuthenticated=false; &#125; &#125;, set_user(state,user)&#123; if(user)&#123; state.user=user; &#125;else&#123; state.user=&#123;&#125;; &#125; &#125; &#125;; const actions=&#123; setAuthenticated:(&#123;commit&#125;,isAuthenticated)=&gt;&#123; commit('set_authenticated',isAuthenticated); &#125;, setUser:(&#123;commit&#125;,user)=&gt;&#123; commit('set_user',user); &#125;, clearCurrentState(&#123;commit&#125;)&#123; commit('set_authenticated',false); commit('set_user',&#123;&#125;); &#125; &#125;;","permalink":"https://codermino.github.io/2020/08/14/vuex%E9%A1%B5%E9%9D%A2%E5%88%B7%E6%96%B0%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E9%97%AE%E9%A2%98/","photos":[]},{"tags":[{"name":"vuex知识点总结","slug":"vuex知识点总结","permalink":"https://codermino.github.io/tags/vuex%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/"}],"title":"vuex知识点总结","date":"2020/08/14","text":"1、vuex主要包括以下几个模块： State：定义了应用状态的数据结构，可以在这里设置默认的初始状态。 Getter：允许组件从 Store 中获取数据，mapGetters 辅助函数仅仅是将 store 中的 getter 映射到局部计算属性。 Mutation：是唯一更改 store 中状态的方法，且必须是同步函数。 Action：用于提交 mutation，而不是直接变更状态，可以包含任意异步操作。 Module：允许将单一的 Store 拆分为多个 store 且同时保存在单一的状态树中。 2、什么情况下使用 Vuex？ 如果应用够简单，最好不要使用 Vuex，一个简单的 store 模式即可 需要构建一个中大型单页应用时，使用Vuex能更好地在组件外部管理状态 3、Vuex和单纯的全局对象有什么区别？ Vuex 的状态存储是响应式的。当 Vue 组件从 store 中读取状态的时候，若 store 中的状态发生变化，那么相应的组件也会相应地得到高效更新。 不能直接改变 store 中的状态。改变 store 中的状态的唯一途径就是显式地提交 (commit) mutation。 这样使得我们可以方便地跟踪每一个状态的变化， 从而让我们能够实现一些工具帮助我们更好地了解我们的应用。 4、为什么 Vuex 的 mutation 中不能做异步操作？ Vuex中所有的状态更新的唯一途径都是mutation，异步操作通过 Action 来提交 mutation实现，这样使得我们可以方便地跟踪每一个状态的变化， 从而让我们能够实现一些工具帮助我们更好地了解我们的应用。 每个mutation执行完成后都会对应到一个新的状态变更，这样devtools就可以打个快照存下来， 然后就可以实现 time-travel 了。如果mutation支持异步操作，就没有办法知道状态是何时更新的， 无法很好的进行状态的追踪，给调试带来困难 5、vuex的action有返回值吗？返回的是什么？ store.dispatch 可以处理被触发的 action 的处理函数返回的 Promise，并且 store.dispatch 仍旧返回 Promise Action 通常是异步的，要知道 action 什么时候结束或者组合多个 action以处理更加复杂的异步流程， 可以通过定义action时返回一个promise对象，就可以在派发action的时候就可以通过处理返回的 Promise处理异步流程。 一个 store.dispatch 在不同模块中可以触发多个 action 函数。在这种情况下，只有当所有触发函数完成后， 返回的 Promise 才会执行。 6、为什么不直接分发mutation,而要通过分发action之后提交 mutation变更状态？ mutation 必须同步执行，我们可以在 action 内部执行异步操作 可以进行一系列的异步操作，并且通过提交 mutation 来记录 action 产生的副作用（即状态变更） 7、从vuex中获取的数据能直接更改吗？ 从vuex中取的数据，不能直接更改，需要浅拷贝对象之后更改，否则报错； 8、Vuex的严格模式是什么,有什么作用,怎么开启 在严格模式下，无论何时发生了状态变更且不是由mutation函数引起的，将会抛出错误。这能保证所有的状态变更都能被调试工具跟踪到。 在Vuex.Store 构造器选项中开启,如下： const store = new Vuex.Store(&#123; strict:true, &#125;) 9、mutation和action有什么区别 action 提交的是 mutation，而不是直接变更状态。mutation可以直接变更状态 action 可以包含任意异步操作。mutation只能是同步操作 提交方式不同 action 是用this.store.dispatch('ACTION_NAME',data)来提交。 mutation是用this.$store.commit('SET_NUMBER',10)来提交 接收参数不同，mutation第一个参数是state，而action第一个参数是context，其包含了 &#123; state, // 等同于 `store.state`，若在模块中则为局部状态 rootState, // 等同于 `store.state`，只存在于模块中 commit, // 等同于 `store.commit` dispatch, // 等同于 `store.dispatch` getters, // 等同于 `store.getters` rootGetters // 等同于 `store.getters`，只存在于模块中 &#125; 10、在v-model上怎么用Vuex中state的值？ &lt;input v-model=\"message\"&gt; computed: &#123; message: &#123; get () &#123; return this.$store.state.message &#125;, set (value) &#123; this.$store.commit('updateMessage', value) &#125; &#125; &#125;","permalink":"https://codermino.github.io/2020/08/14/vuex%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/","photos":[]},{"tags":[{"name":"响应式布局尺寸划分","slug":"响应式布局尺寸划分","permalink":"https://codermino.github.io/tags/%E5%93%8D%E5%BA%94%E5%BC%8F%E5%B8%83%E5%B1%80%E5%B0%BA%E5%AF%B8%E5%88%92%E5%88%86/"}],"title":"响应式布局尺寸划分","date":"2020/08/14","text":"尺寸划分 超小屏幕(手机) ------- &lt;768px 设置宽度为100% 小屏设备(平板) ------- &gt;=768px &lt;992px 设置宽度为750px 中等屏幕(桌面显示器) ------- &gt;=992px &lt;1200px 设置宽度为970px 宽屏设备(大桌面显示器) ------- &gt;=1200px 设置宽度为1170px","permalink":"https://codermino.github.io/2020/08/14/%E5%93%8D%E5%BA%94%E5%BC%8F%E5%B8%83%E5%B1%80%E5%B0%BA%E5%AF%B8%E5%88%92%E5%88%86/","photos":[]},{"tags":[{"name":"echarts自定义样式","slug":"echarts自定义样式","permalink":"https://codermino.github.io/tags/echarts%E8%87%AA%E5%AE%9A%E4%B9%89%E6%A0%B7%E5%BC%8F/"}],"title":"echarts自定义样式","date":"2020/08/14","text":"一、折线统计图中的自定义样式（注意背景条纹色的设置） let option1 = &#123; title: &#123; // text: \"堆叠区域图\" &#125;, tooltip: &#123; trigger: \"axis\", axisPointer: &#123; type: \"cross\", label: &#123; backgroundColor: \"#6a7985\" &#125; &#125; &#125;, legend: &#123; data: [\"登记数\", \"分享数\"] &#125;, toolbox: &#123;&#125;, grid: &#123; left: 10, right: 10, bottom: 20, top: 30, containLabel: true &#125;, color: [\"#81b22f\", \"#f3d71c\", \"#f4b9a9\"], xAxis: [ &#123; type: \"category\", boundaryGap: false, data: [\"周一\", \"周二\", \"周三\", \"周四\", \"周五\", \"周六\", \"周日\"] &#125; ], yAxis: [ &#123; type: \"value\", splitArea: &#123; show: true, areaStyle:&#123; color:['rgba(255,255,255,0.3)','rgba(241,241,241,0.3)'] &#125; &#125; &#125; ], series: [ &#123; name: \"登记数\", type: \"line\", stack: \"总量\", animationEasing: \"quadraticOut\", label: &#123; normal: &#123; // show: true, position: \"top\" &#125; &#125;, itemStyle: &#123; normal: &#123; color: \"#3888fa\", lineStyle: &#123; color: \"#3888fa\", width: 2 &#125;, areaStyle: &#123; color: \"#f3f8ff\" &#125; &#125; &#125;, data: [820, 932, 901, 934, 1290, 1330, 1320], animationDuration: 2800, animationEasing: \"cubicInOut\" &#125;, &#123; name: \"分享数\", type: \"line\", stack: \"总量\", itemStyle: &#123; normal: &#123; color: \"#FF005A\", lineStyle: &#123; color: \"#FF005A\", width: 2 &#125; &#125; &#125;, data: [350, 432, 601, 554, 390, 430, 410], animationDuration: 2800, animationEasing: \"cubicInOut\" &#125; ] &#125;; 二、雷达图自定义样式 let option2 = &#123; tooltip: &#123; trigger: \"axis\", axisPointer: &#123; // 坐标轴指示器，坐标轴触发有效 type: \"shadow\" // 默认为直线，可选为：'line' | 'shadow' &#125; &#125;, radar: &#123; radius: \"66%\", center: [\"50%\", \"42%\"], splitNumber: 8, splitArea: &#123; areaStyle: &#123; color: \"rgba(127,95,132,.3)\", opacity: 1, shadowBlur: 45, shadowColor: \"rgba(0,0,0,.5)\", shadowOffsetX: 0, shadowOffsetY: 15 &#125; &#125;, indicator: [ &#123; name: \"Sales\", max: 10000 &#125;, &#123; name: \"Administration\", max: 20000 &#125;, &#123; name: \"Information Technology\", max: 20000 &#125;, &#123; name: \"Customer Support\", max: 20000 &#125;, &#123; name: \"Development\", max: 20000 &#125;, &#123; name: \"Marketing\", max: 20000 &#125; ] &#125;, legend: &#123; left: \"center\", bottom: \"10\", data: [\"Allocated Budget\", \"Expected Spending\", \"Actual Spending\"] &#125;, series: [ &#123; type: \"radar\", symbolSize: 0, areaStyle: &#123; normal: &#123; shadowBlur: 13, shadowColor: \"rgba(0,0,0,.2)\", shadowOffsetX: 0, shadowOffsetY: 10, opacity: 1 &#125; &#125;, data: [ &#123; value: [5000, 7000, 12000, 11000, 15000, 14000], name: \"Allocated Budget\", itemStyle: &#123; normal: &#123; color: \"#2ec7c9\", areaStyle: &#123; type: \"default\", // opacity: 0.8, // 图表中各个图区域的透明度 color: \"#5ab1ef\" // 图表中各个图区域的颜色 &#125; &#125; &#125; &#125;, &#123; value: [4000, 9000, 15000, 15000, 13000, 11000], itemStyle: &#123; normal: &#123; color: \"#b6a2de\" // areaStyle: &#123; // type: \"default\", // // opacity: 0.8, // 图表中各个图区域的透明度 // color: \"#b6a2de\" // 图表中各个图区域的颜色 // &#125; &#125; &#125;, name: \"Expected Spending\" &#125;, &#123; value: [5500, 11000, 12000, 15000, 12000, 12000], name: \"Actual Spending\", itemStyle: &#123; normal: &#123; color: \"#5ab1ef\", areaStyle: &#123; type: \"default\", // opacity: 0.8, // 图表中各个图区域的透明度 color: \"#2ec7c9\" // 图表中各个图区域的颜色 &#125; &#125; &#125; &#125; ], animationDuration: 3000 &#125; ] &#125;; 三、玫瑰图自定义样式 let option3 = &#123; tooltip: &#123; trigger: \"item\", formatter: \"&#123;a&#125; &lt;br/&gt;&#123;b&#125; : &#123;c&#125; (&#123;d&#125;%)\" &#125;, legend: &#123; left: \"center\", bottom: \"10\", data: [\"Industries\", \"Technology\", \"Forex\", \"Gold\", \"Forecasts\"] &#125;, series: [ &#123; name: \"WEEKLY WRITE ARTICLES\", type: \"pie\", roseType: \"radius\", radius: [15, 95], center: [\"50%\", \"38%\"], color: [\"#2ec7c9\", \"#b6a2de\", \"#5ab1ef\", \"#ffb980\", \"#d87a80\"], data: [ &#123; value: 320, name: \"Industries\" &#125;, &#123; value: 240, name: \"Technology\" &#125;, &#123; value: 149, name: \"Forex\" &#125;, &#123; value: 100, name: \"Gold\" &#125;, &#123; value: 59, name: \"Forecasts\" &#125; ], animationEasing: \"cubicInOut\", animationDuration: 2600 &#125; ] &#125;; 四、柱形图自定义样式（注意背景条纹色的设置） let option4 = &#123; tooltip: &#123; trigger: \"axis\", axisPointer: &#123; // 坐标轴指示器，坐标轴触发有效 type: \"shadow\" // 默认为直线，可选为：'line' | 'shadow' &#125; &#125;, // backgroundColor: &#123;&#125;, grid: &#123; top: 10, left: \"2%\", right: \"2%\", bottom: \"3%\", containLabel: true &#125;, xAxis: [ &#123; type: \"category\", data: [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"], axisTick: &#123; alignWithLabel: true &#125; &#125; ], yAxis: [ &#123; type: \"value\", axisTick: &#123; show: false &#125;, splitArea: &#123; show: true, areaStyle:&#123; color:['rgba(255,255,255,0.3)','rgba(241,241,241,0.3)'] &#125; &#125; &#125; ], series: [ &#123; name: \"pageA\", type: \"bar\", stack: \"vistors\", barWidth: \"60%\", itemStyle: &#123; normal: &#123; color: \"#2ec7c9\" &#125; &#125;, data: [79, 52, 200, 334, 390, 330, 220], animationDuration: 6000 &#125;, &#123; name: \"pageB\", type: \"bar\", stack: \"vistors\", barWidth: \"60%\", itemStyle: &#123; normal: &#123; color: \"#b6a2de\" &#125; &#125;, data: [80, 52, 200, 334, 390, 330, 220], animationDuration: 6000 &#125;, &#123; name: \"pageC\", type: \"bar\", stack: \"vistors\", barWidth: \"60%\", itemStyle: &#123; normal: &#123; color: \"#1e9fff\" &#125; &#125;, data: [30, 52, 200, 334, 390, 330, 220], animationDuration: 6000 &#125; ] &#125;;","permalink":"https://codermino.github.io/2020/08/14/echarts%E8%87%AA%E5%AE%9A%E4%B9%89%E6%A0%B7%E5%BC%8F/","photos":[]},{"tags":[{"name":"在本地运行webpack打包后的vue项目文件","slug":"在本地运行webpack打包后的vue项目文件","permalink":"https://codermino.github.io/tags/%E5%9C%A8%E6%9C%AC%E5%9C%B0%E8%BF%90%E8%A1%8Cwebpack%E6%89%93%E5%8C%85%E5%90%8E%E7%9A%84vue%E9%A1%B9%E7%9B%AE%E6%96%87%E4%BB%B6/"}],"title":"在本地运行webpack打包后的vue项目文件","date":"2020/08/14","text":"那么如何用最简单的方法就可以让打包后的文件正常运行呢？ 解决这个问题首先要安装server，在cmd中输入命令： npm install -g serve 进入项目目录使用：serve -s dist 这时会提示要访问的网址，在浏览器中输入网址就可以打开了！","permalink":"https://codermino.github.io/2020/08/14/%E5%9C%A8%E6%9C%AC%E5%9C%B0%E8%BF%90%E8%A1%8Cwebpack%E6%89%93%E5%8C%85%E5%90%8E%E7%9A%84vue%E9%A1%B9%E7%9B%AE%E6%96%87%E4%BB%B6/","photos":[]},{"tags":[{"name":"vue.config.js配置","slug":"vue-config-js配置","permalink":"https://codermino.github.io/tags/vue-config-js%E9%85%8D%E7%BD%AE/"}],"title":"vue.config.js配置","date":"2020/08/14","text":"简易版 const path = require(\"path\"); const resolve = function(dir) &#123; return path.join(__dirname, dir); &#125;; module.exports = &#123; publicPath: process.env.NODE_ENV === \"production\" ? \"./\" : \"./\", outputDir: \"dist\", assetsDir: \"static\", lintOnSave: true, // 是否开启eslint保存检测 productionSourceMap: false, // 是否在构建生产包时生成sourcdeMap chainWebpack: config =&gt; &#123; config.resolve.alias .set(\"@\", resolve(\"src\")) .set(\"@v\", resolve(\"src/views\")) .set(\"@c\", resolve(\"src/components\")) .set(\"@u\", resolve(\"src/utils\")) .set(\"@s\", resolve(\"src/service\")); /* 别名配置 */ config.optimization.runtimeChunk(\"single\"); &#125;, devServer: &#123; // host: \"localhost\", /* 本地ip地址 */ //host: \"192.168.1.107\", host: \"0.0.0.0\", //局域网和本地访问 port: \"8080\", hot: true, /* 自动打开浏览器 */ open: false, overlay: &#123; warning: false, error: true &#125;, /* 跨域代理 */ proxy: &#123; \"/api\": &#123; /* 目标代理服务器地址 */ target: \"http://xxx.com\", // // target: \"http://localhost:8888\", // /* 允许跨域 */ changeOrigin: true, ws: true, pathRewrite: &#123; \"^/api\": \"\" &#125; &#125; &#125; &#125; &#125;; 完整版 const path = require(\"path\"); const UglifyPlugin = require(\"uglifyjs-webpack-plugin\"); module.exports = &#123; // 基本路径 /* 部署生产环境和开发环境下的URL：可对当前环境进行区分，baseUrl 从 Vue CLI 3.3 起已弃用，要使用publicPath */ /* baseUrl: process.env.NODE_ENV === 'production' ? './' : '/' */ publicPath: process.env.NODE_ENV === \"production\" ? \"./\" : \"./\", // 输出文件目录 outputDir: \"dist\", // eslint-loader 是否在保存的时候检查 lintOnSave: true, // use the full build with in-browser compiler? // https://vuejs.org/v2/guide/installation.html#Runtime-Compiler-vs-Runtime-only // compiler: false, runtimeCompiler: true, //关键点在这 // 调整内部的 webpack 配置。 // 查阅 https://github.com/vuejs/vue-doc-zh-cn/vue-cli/webpack.md // webpack配置 // see https://github.com/vuejs/vue-cli/blob/dev/docs/webpack.md chainWebpack: () =&gt; &#123;&#125;, configureWebpack: config =&gt; &#123; if (process.env.NODE_ENV === \"production\") &#123; // 为生产环境修改配置... config.mode = \"production\"; // 将每个依赖包打包成单独的js文件 var optimization = &#123; runtimeChunk: \"single\", splitChunks: &#123; chunks: \"all\", maxInitialRequests: Infinity, minSize: 20000, // 依赖包超过20000bit将被单独打包 cacheGroups: &#123; vendor: &#123; test: /[\\\\/]node_modules[\\\\/]/, name(module) &#123; // get the name. E.g. node_modules/packageName/not/this/part.js // or node_modules/packageName const packageName = module.context.match( /[\\\\/]node_modules[\\\\/](.*?)([\\\\/]|$)/ )[1]; // npm package names are URL-safe, but some servers don't like @ symbols return `npm.$&#123;packageName.replace(\"@\", \"\")&#125;`; &#125; &#125; &#125; &#125;, minimizer: [ new UglifyPlugin(&#123; uglifyOptions: &#123; compress: &#123; warnings: false, drop_console: true, // console drop_debugger: false, pure_funcs: [\"console.log\"] // 移除console &#125; &#125; &#125;) ] &#125;; Object.assign(config, &#123; optimization &#125;); &#125; else &#123; // 为开发环境修改配置... config.mode = \"development\"; var optimization2 = &#123; runtimeChunk: \"single\", splitChunks: &#123; chunks: \"all\", maxInitialRequests: Infinity, minSize: 20000, // 依赖包超过20000bit将被单独打包 cacheGroups: &#123; vendor: &#123; test: /[\\\\/]node_modules[\\\\/]/, name(module) &#123; // get the name. E.g. node_modules/packageName/not/this/part.js // or node_modules/packageName const packageName = module.context.match( /[\\\\/]node_modules[\\\\/](.*?)([\\\\/]|$)/ )[1]; // npm package names are URL-safe, but some servers don't like @ symbols return `npm.$&#123;packageName.replace(\"@\", \"\")&#125;`; &#125; &#125; &#125; &#125; &#125;; &#125; Object.assign(config, &#123; // 开发生产共同配置 // externals: &#123; // 'vue': 'Vue', // 'element-ui': 'ELEMENT', // 'vue-router': 'VueRouter', // 'vuex': 'Vuex' // &#125; // 防止将某些 import 的包(package)打包到 bundle 中，而是在运行时(runtime)再去从外部获取这些扩展依赖(用于csdn引入) resolve: &#123; extensions: [\".js\", \".vue\", \".json\"], //文件优先解析后缀名顺序 alias: &#123; \"@\": path.resolve(__dirname, \"./src\"), \"@c\": path.resolve(__dirname, \"./src/components\"), \"@v\": path.resolve(__dirname, \"./src/views\"), \"@u\": path.resolve(__dirname, \"./src/utils\"), \"@s\": path.resolve(__dirname, \"./src/service\") &#125;, // 别名配置 plugins: [] &#125;, optimization: optimization2 &#125;); &#125;, // vue-loader 配置项 // https://vue-loader.vuejs.org/en/options.html // vueLoader: &#123;&#125;, // 生产环境是否生成 sourceMap 文件 productionSourceMap: false, // css相关配置 css: &#123; // 是否使用css分离插件 ExtractTextPlugin // extract: true, //注释css热更新生效 // 开启 CSS source maps? sourceMap: false, // css预设器配置项 loaderOptions: &#123;&#125;, // 启用 CSS modules for all css / pre-processor files. modules: false &#125;, // use thread-loader for babel &amp; TS in production build // enabled by default if the machine has more than 1 cores parallel: require(\"os\").cpus().length &gt; 1, // 是否启用dll // See https://github.com/vuejs/vue-cli/blob/dev/docs/cli-service.md#dll-mode // dll: false, // PWA 插件相关配置 // see https://github.com/vuejs/vue-cli/tree/dev/packages/%40vue/cli-plugin-pwa pwa: &#123;&#125;, // webpack-dev-server 相关配置 devServer: &#123; /* 自动打开浏览器 */ open: false, // host: \"192.168.0.137\", host: \"0.0.0.0\", //局域网和本地访问 //host: \"192.168.1.137\", port: 8080, https: false, hotOnly: false, /* 使用代理 */ proxy: &#123; \"/api\": &#123; /* 目标代理服务器地址 */ // target: \"http://192.168.0.106:8080/\", target: \"http://192.168.1.126:8080/\", //阳洋 /* 允许跨域 */ changeOrigin: true, ws: true, pathRewrite: &#123; \"^/api\": \"\" &#125; &#125; &#125;, before: () =&gt; &#123;&#125; &#125;, // 第三方插件配置 pluginOptions: &#123;&#125; &#125;; 之后运行打包命令即可 npm run build 清除缓存 tip: 直接在vue项目中新建vue.config.js，然后复制进去即可。 const path = require(\"path\"); // 获取当前时间戳 const Timestamp = new Date().getTime(); // 定义版本号 const VUE_APP_Version = '1.0.0' const resolve = function (dir) &#123; return path.join(__dirname, dir); &#125;; module.exports = &#123; configureWebpack: &#123; output: &#123; //输出重构，打包编译后的文件名称 【模块名称.版本号.时间戳】 filename: `[name].$&#123;VUE_APP_Version&#125;.$&#123;Timestamp&#125;.js`, chunkFilename: `[name].$&#123;VUE_APP_Version&#125;.$&#123;Timestamp&#125;.js` &#125; &#125;, publicPath: process.env.NODE_ENV === \"production\" ? \"./\" : \"./\", // publicPath: './', outputDir: \"dist\", assetsDir: \"static\", lintOnSave: true, // 是否开启eslint保存检测 productionSourceMap: false, // 是否在构建生产包时生成sourcdeMap chainWebpack: config =&gt; &#123; config.resolve.alias .set(\"@\", resolve(\"src\")) .set(\"@v\", resolve(\"src/views\")) .set(\"@c\", resolve(\"src/components\")) .set(\"@u\", resolve(\"src/utils\")) .set(\"@s\", resolve(\"src/service\")); /* 别名配置 */ config.optimization.runtimeChunk(\"single\"); &#125;, devServer: &#123; // host: \"localhost\", /* 本地ip地址 */ //host: \"192.168.1.107\", host: \"0.0.0.0\", //局域网和本地访问 port: \"8080\", hot: true, /* 自动打开浏览器 */ open: false, overlay: &#123; warning: false, error: true &#125;, /* 跨域代理 */ proxy: &#123; \"/api\": &#123; /* 目标代理服务器地址 */ target: \"http://m260048y71.zicp.vip\", // // target: \"http://192.168.1.102:8888\", // /* 允许跨域 */ changeOrigin: true, ws: true, pathRewrite: &#123; \"^/api\": \"\" &#125; &#125; &#125; &#125; &#125;;","permalink":"https://codermino.github.io/2020/08/14/vue-config-js%E9%85%8D%E7%BD%AE/","photos":[]},{"tags":[{"name":"ecahrts自适应和切换问题","slug":"ecahrts自适应和切换问题","permalink":"https://codermino.github.io/tags/ecahrts%E8%87%AA%E9%80%82%E5%BA%94%E5%92%8C%E5%88%87%E6%8D%A2%E9%97%AE%E9%A2%98/"}],"title":"ecahrts自适应和切换问题","date":"2020/08/14","text":"1、解决方法：监听屏幕的 onresize() 事件调用Echarts的resize()事件,代码如下： // 自适应屏幕宽度 window.onresize = function() &#123; myChart.resize(); myChart2.resize(); myChart3.resize(); myChart4.resize(); &#125;; 2、不要页面一加载就全部把页面中的图表都加载好，而是刚开始只渲染默认的第一个图表，其他的图表在tabs选项卡切换的时候再加载渲染出来就可以了，具体代码如下： &lt;template&gt; &lt;!-- 使用tabs选项卡子组件 --&gt; &lt;titleBar :indexRenshiMsg=\"renshiMsg\" @func=\"changeHandle\"&gt;&lt;/titleBar&gt; &lt;el-row style=\"margin-top:20px\"&gt; &lt;div id=\"renshichu\" :style=\"&#123;width: '100%', height: '400px'&#125;\"&gt;&lt;/div&gt; &lt;/el-row&gt; &lt;!-- 使用子组件 --&gt; &lt;titleBar :indexRenshiMsg=\"renshiMsg\" @func=\"changeHandle2\"&gt;&lt;/titleBar&gt; &lt;el-row style=\"margin-top:20px\"&gt; &lt;div id=\"zhinengbu\" :style=\"&#123;width: '100%', height: '400px'&#125;\"&gt;&lt;/div&gt; &lt;/el-row&gt; &lt;!-- 部门管理员权限 --&gt; &lt;titleBar :indexRenshiMsg=\"renshiMsg\" @func=\"changeHandle3\"&gt;&lt;/titleBar&gt; &lt;el-row style=\"margin-top:20px\"&gt; &lt;div id=\"bumengguanli\" :style=\"&#123;width: '100%', height: '400px'&#125;\"&gt;&lt;/div&gt; &lt;/el-row&gt; &lt;/template&gt; &lt;script&gt; import titleBar from \"../components/titleBar\"; // 指定图表的配置项和数据 var option = &#123; tooltip: &#123; trigger: \"axis\", axisPointer: &#123; type: \"cross\", crossStyle: &#123; color: \"#999\" &#125; &#125; &#125;, toolbox: &#123; feature: &#123; dataView: &#123; show: true, readOnly: false &#125;, magicType: &#123; show: true, type: [\"line\", \"bar\"] &#125;, restore: &#123; show: true &#125;, saveAsImage: &#123; show: true &#125; &#125; &#125;, color: [\"#3398DB\"], tooltip: &#123;&#125;, legend: &#123; data: [\"申报人数\"], left: \"left\", top: \"10%\", textStyle: &#123; fontSize: 16 &#125; &#125;, xAxis: &#123; data: [\"教授\", \"副教授\", \"讲师\", \"研究员\", \"副研究员\", \"助理研究员\"], axisLabel: &#123; fontSize: 20 //字体大小 &#125; &#125;, yAxis: [ &#123; type: \"value\", name: \"人数\", axisLabel: &#123; formatter: \"&#123;value&#125;\", fontSize: 20 //字体大小 &#125; &#125; ], series: [ &#123; barWidth: 50, name: \"申报人数\", type: \"bar\", data: [10, 3, 4, 4, 5, 4] &#125; ] &#125;; var option2 = &#123; tooltip: &#123; trigger: \"axis\", axisPointer: &#123; type: \"cross\", crossStyle: &#123; color: \"#999\" &#125; &#125; &#125;, toolbox: &#123; feature: &#123; dataView: &#123; show: true, readOnly: false &#125;, magicType: &#123; show: true, type: [\"line\", \"bar\"] &#125;, restore: &#123; show: true &#125;, saveAsImage: &#123; show: true &#125; &#125; &#125;, tooltip: &#123; trigger: \"axis\", axisPointer: &#123; type: \"cross\", crossStyle: &#123; color: \"#999\" &#125; &#125; &#125;, legend: &#123; data: [\"已审核\", \"未审核\", \"退回\"], left: \"left\", top: \"10%\", orient: \"vertical\", textStyle: &#123; fontSize: 20 &#125; &#125;, xAxis: &#123; type: \"category\", data: [\"论文著作\", \"项目获批\", \"荣誉获奖\"], axisPointer: &#123; type: \"shadow\" &#125;, axisLabel: &#123; fontSize: 20 //字体大小 &#125; &#125;, yAxis: [ &#123; type: \"value\", name: \"人数\", axisLabel: &#123; formatter: \"&#123;value&#125;\", fontSize: 20 //字体大小 &#125; &#125; ], series: [ &#123; barWidth: 50, name: \"已审核\", type: \"bar\", color: \"#92d050\", data: [10, 8, 6] &#125;, &#123; barWidth: 50, name: \"未审核\", type: \"bar\", color: \"#ed7d31\", data: [7, 5, 3] &#125;, &#123; barWidth: 50, name: \"退回\", type: \"bar\", color: \"#9cc3e5\", data: [4, 3, 1] &#125; ] &#125;; var option4 = &#123; tooltip: &#123; trigger: \"axis\", axisPointer: &#123; type: \"cross\", crossStyle: &#123; color: \"#999\" &#125; &#125; &#125;, toolbox: &#123; feature: &#123; dataView: &#123; show: true, readOnly: false &#125;, magicType: &#123; show: true, type: [\"line\", \"bar\"] &#125;, restore: &#123; show: true &#125;, saveAsImage: &#123; show: true &#125; &#125; &#125;, color: [\"#3398DB\"], tooltip: &#123;&#125;, legend: &#123; data: [\"数量\"], left: \"left\", top: \"10%\", textStyle: &#123; fontSize: 20 &#125; &#125;, xAxis: &#123; data: [\"论文发表\", \"著作发表\", \"项目立项\", \"获奖荣誉\", \"教学课程\"], axisLabel: &#123; fontSize: 20 //字体大小 &#125; &#125;, yAxis: [ &#123; type: \"value\", name: \"数量\", axisLabel: &#123; formatter: \"&#123;value&#125;\", fontSize: 20 //字体大小 &#125; &#125; ], series: [ &#123; barWidth: 50, name: \"数量\", type: \"bar\", data: [12, 4, 7, 4, 9, 33] &#125; ] &#125;; export default &#123; components: &#123; titleBar &#125;, name: \"index\", data() &#123; return &#123; num: 115, onePower: true, echartsTitle: \"评审年度 | 2020年\", echartsTitle4: \"个人档案库内情况\", xAxis: [\"教授\", \"副教授\", \"讲师\", \"研究员\", \"副研究员\", \"助理研究员\"], xAxis2: [\"论文著作\", \"项目获批\", \"荣誉获奖\"], xAxis4: [\"论文发表\", \"著作发表\", \"项目立项\", \"获奖荣誉\", \"教学课程\"], series: [10, 3, 4, 4, 5, 4], // 步骤条进度 active: 1, // 待办事项 backlog: 4, // 传给子组件的参数 renshiMsg: &#123; title: \"评审年度 | 2020年\", msg: \"申报人数：\", number: 49 &#125;, chartOptions: [option, option2, option4], tableData: [ &#123; category: \"论文\", research: \"基于C51单片机的全球导弹发射控制系统\", opinion: \"这是一个非常好的想法\", name: \"张三\" &#125;, &#123; category: \"项目\", research: \"基于C51单片机的全球导弹发射控制系统\", opinion: \"这是一个非常好的想法\", name: \"张三\" &#125;, &#123; category: \"获奖\", research: \"全球和平伟大贡献奖\", opinion: \"这是一个非常好的想法\", name: \"张三\" &#125;, &#123; category: \"论文\", research: \"基于C51单片机的全球导弹发射控制系统\", opinion: \"这是一个非常好的想法\", name: \"张三\" &#125;, &#123; category: \"论文\", research: \"基于C51单片机的全球导弹发射控制系统\", opinion: \"这是一个非常好的想法\", name: \"张三\" &#125; ] &#125;; &#125;, mounted() &#123; // 人事处管理员审核权限统计图 var dom = document.getElementById(\"renshichu\"); var myChart = this.echarts.init(dom); myChart.setOption(this.chartOptions[0]); // 职能部门审核用户权限统计图 var dom2 = document.getElementById(\"zhinengbu\"); var myChart2 = this.echarts.init(dom2); myChart2.setOption(this.chartOptions[1]); // 部门管理员权限统计图 var dom3 = document.getElementById(\"bumengguanli\"); var myChart3 = this.echarts.init(dom3); myChart3.setOption(this.chartOptions[2]); // 普通教师权限统计图 var dom4 = document.getElementById(\"jiaoshiquanxian\"); var myChart4 = this.echarts.init(dom4); myChart4.setOption(this.chartOptions[2]); // 自适应屏幕宽度 window.onresize = function() &#123; myChart.resize(); myChart2.resize(); myChart3.resize(); myChart4.resize(); &#125;; &#125;, methods: &#123; // 下面的几个函数都是tabs选项卡切换的点击事件 changeHandle(e) &#123; // 人事处管理员审核权限统计图 var dom = document.getElementById(\"renshichu\"); var myChart = this.echarts.init(dom); myChart.clear(); myChart.setOption(this.chartOptions[e]); &#125;, changeHandle2(e) &#123; // 职能部门审核用户权限统计图 var dom2 = document.getElementById(\"zhinengbu\"); var myChart2 = this.echarts.init(dom2); myChart2.clear(); myChart2.setOption(this.chartOptions[e]); &#125;, changeHandle3(e) &#123; // 职能部门审核用户权限统计图 var dom3 = document.getElementById(\"bumengguanli\"); var myChart3 = this.echarts.init(dom3); myChart3.clear(); myChart3.setOption(this.chartOptions[e]); &#125; &#125; &#125;; &lt;/script&gt;","permalink":"https://codermino.github.io/2020/08/14/ecahrts%E8%87%AA%E9%80%82%E5%BA%94%E5%92%8C%E5%88%87%E6%8D%A2%E9%97%AE%E9%A2%98/","photos":[]},{"tags":[{"name":"scrapy的shell的使用","slug":"scrapy的shell的使用","permalink":"https://codermino.github.io/tags/scrapy%E7%9A%84shell%E7%9A%84%E4%BD%BF%E7%94%A8/"}],"title":"scrapy的shell的使用","date":"2020/07/26","text":"scrapy shell 网址 然后可以在Terminal中使用tab键进行代码提示(但是可能会出现warning等提示信息，扰乱界面) 可以在settings.py中 import logging logging.getLogger('parso').setLevel(logging.WARNING)","permalink":"https://codermino.github.io/2020/07/26/scrapy%E7%9A%84shell%E7%9A%84%E4%BD%BF%E7%94%A8/","photos":[]},{"tags":[{"name":"scrapy添加cookie的三种方式","slug":"scrapy添加cookie的三种方式","permalink":"https://codermino.github.io/tags/scrapy%E6%B7%BB%E5%8A%A0cookie%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F/"}],"title":"scrapy添加cookie的三种方式","date":"2020/07/26","text":"settings中添加 settings文件中给Cookies_enabled=False解注释 settings的headers配置的cookie就可以用了 这种方法最简单，同时cookie可以直接粘贴浏览器的。 后两种方法添加的cookie是字典格式的，需要用json反序列化一下, 而且需要设置settings中的Cookies_enabled=True eq:cookie = &#123;k1: v1, k2: v2&#125; DownloadMiddleware中添加 settings中给downloadmiddleware解注释 去中间件文件中找downloadmiddleware这个类， 修改process_request，添加request.cookies=&#123;&#125;即可。 爬虫主文件中重写start_request def start_requests(self): yield scrapy.Request(url,dont_filter=True,cookies=&#123;自己的cookie&#125;) 方法三的Demo1 import scrapy class ItaobaoSpider(scrapy.Spider): name = 'itaobao' allowed_domains = ['taobao.com'] # start_urls = ['https://cart.taobao.com/cart.htm?spm=a1z02.1.a2109.d1000367.OOeipq&amp;nekot=1470211439694'] # 需要重写start_requests方法 def start_requests(self): url = \"https://cart.taobao.com/cart.htm?spm=a1z02.1.a2109.d1000367.OOeipq&amp;nekot=1470211439694\" # 此处的cookie为手动登录后从浏览器粘贴下来的值 cookie = \"thw=cn; cookie2=16b0fe13709f2a71dc06ab1f15dcc97b; _tb_token_=fe3431e5fe755;\" \\ \" _samesite_flag_=true; ubn=p; ucn=center; t=538b39347231f03177d588275aba0e2f;\" \\ \" tk_trace=oTRxOWSBNwn9dPyorMJE%2FoPdY8zfvmw%2Fq5hoqmmiKd74AJ%2Bt%2FNCZ%\" \\ \"2FSIX9GYWSRq4bvicaWHhDMtcR6rWsf0P6XW5ZT%2FgUec9VF0Ei7JzUpsghuwA4cBMNO9EHkGK53r%\" \\ \"2Bb%2BiCEx98Frg5tzE52811c%2BnDmTNlzc2ZBkbOpdYbzZUDLaBYyN9rEdp9BVnFGP1qVAAtbsnj35zfBVfe09E%\" \\ \"2BvRfUU823q7j4IVyan1lagxILINo%2F%2FZK6omHvvHqA4cu2IaVAhy5MzzodyJhmXmOpBiz9Pg%3D%3D; \" \\ \"cna=5c3zFvLEEkkCAW8SYSQ2GkGo; sgcookie=E3EkJ6LRpL%2FFRZIBoXfnf; unb=578051633; \" \\ \"uc3=id2=Vvl%2F7ZJ%2BJYNu&amp;nk2=r7kpR6Vbl9KdZe14&amp;lg2=URm48syIIVrSKA%3D%3D&amp;vt3=F8dBxGJsy36E3EwQ%2BuQ%3D;\" \\ \" csg=c99a3c3d; lgc=%5Cu5929%5Cu4ED9%5Cu8349%5Cu5929%5Cu4ED9%5Cu8349; cookie17=Vvl%2F7ZJ%2BJYNu;\" \\ \" dnk=%5Cu5929%5Cu4ED9%5Cu8349%5Cu5929%5Cu4ED9%5Cu8349; skt=4257a8fa00b349a7; existShop=MTU5MzQ0MDI0MQ%3D%3D;\" \\ \" uc4=nk4=0%40rVtT67i5o9%2Bt%2BQFc65xFQrUP0rGVA%2Fs%3D&amp;id4=0%40VH93OXG6vzHVZgTpjCrALOFhU4I%3D;\" \\ \" tracknick=%5Cu5929%5Cu4ED9%5Cu8349%5Cu5929%5Cu4ED9%5Cu8349; _cc_=W5iHLLyFfA%3D%3D; \" \\ \"_l_g_=Ug%3D%3D; sg=%E8%8D%893d; _nk_=%5Cu5929%5Cu4ED9%5Cu8349%5Cu5929%5Cu4ED9%5Cu8349;\" \\ \" cookie1=VAmiexC8JqC30wy9Q29G2%2FMPHkz4fpVNRQwNz77cpe8%3D; tfstk=cddPBI0-Kbhyfq5IB_1FRmwX4zaRClfA\" \\ \"_qSREdGTI7eLP5PGXU5c-kQm2zd2HGhcE; mt=ci=8_1; v=0; uc1=cookie21=VFC%2FuZ9ainBZ&amp;cookie15=VFC%2FuZ9ayeYq2g%3D%3D&amp;cookie\" \\ \"16=WqG3DMC9UpAPBHGz5QBErFxlCA%3D%3D&amp;existShop=false&amp;pas=0&amp;cookie14=UoTV75eLMpKbpQ%3D%3D&amp;cart_m=0;\" \\ \" _m_h5_tk=cbe3780ec220a82fe10e066b8184d23f_1593451560729; _m_h5_tk_enc=c332ce89f09d49c68e13db9d906c8fa3; \" \\ \"l=eBxAcQbPQHureJEzBO5aourza7796IRb8sPzaNbMiInca6MC1hQ0PNQD5j-MRdtjgtChRe-PWBuvjdeBWN4dbNRMPhXJ_n0xnxvO.; \" \\ \"isg=BJ2drKVLn8Ww-Ht9N195VKUWrHmXutEMHpgqKF9iKfRAFrxIJAhD3DbMRAoQ1unE\" cookies = &#123;&#125; # 提取键值对 请求头中携带cookie必须是一个字典，所以要把原生的cookie字符串转换成cookie字典 for cookie in cookie.split(';'): key, value = cookie.split(\"=\", 1) cookies[key] = value yield scrapy.Request(url=url, cookies=cookies, callback=self.parse) def parse(self, response): print(response.text) 方法三的Demo1的最终cookie的dict形式 cookie = &#123;'ll': '\"108090\"', ' bid': 'LKyRKxbzn_E', ' _pk_ses.100001.8cb4': '*', ' __utma': '30149280.1348080368.1556600783.1556600783.1556600783.1', ' __utmc': '30149280', ' __utmz': '30149280.1556600783.1.1.utmcsr', ' __utmt': '1', ' dbcl2': '\"177745320:ER12/4y8Vxk\"', ' ck': '9SGi', ' _pk_id.100001.8cb4': 'fc3beca6f0344a06.1556600779.1.1556600805.1556600779.', ' push_noty_num': '0', ' push_doumail_num': '0', ' __utmv': '30149280.17774', ' __utmb': '30149280.3.10.1556600783', ' ap_v': '0,6.0'&#125; def start_requests(self): yield scrapy.Request(self.profile_url, callback=self.parse_profile, cookies=self.cookie) 方法三的Demo2 def start_requests(self): \"\"\" 根据cookies模拟登陆人人网，注意settings.py文件的cookies必须是开启的 :return: \"\"\" cookies=\"anonymid=jxcn09d5-vd52v0; depovince=GUZ; _r01_=1; ick_login=d41bb8a9-056b-41a7-b187-7c706f0f8702; ick=39b091b8-f882-499b-992b-34a682d3469a; JSESSIONID=abcHJrhG1CAIo64PJRrUw; jebe_key=9ca5b44f-aaec-4180-962e-bf7581ad6e5e%7Cc1d85b293dafa0e44367ceed107b877e%7C1561517245262%7C1%7C1561517244004; jebe_key=9ca5b44f-aaec-4180-962e-bf7581ad6e5e%7Cc1d85b293dafa0e44367ceed107b877e%7C1561517245262%7C1%7C1561517244011; wp_fold=0; td_cookie=18446744069457827825; jebecookies=e9de8580-fb15-4891-b7c3-7c08ebb41f5c|||||; _de=AE9934B6C85831351B86F7DDD5B20F8A; p=b25ab0edb69343d7f80c5e481864b8c30; first_login_flag=1; ln_uact=18620028487; ln_hurl=http://head.xiaonei.com/photos/0/0/men_main.gif; t=b8a0d848e228dd51d2c84609f814495b0; societyguester=b8a0d848e228dd51d2c84609f814495b0; id=971298880; xnsid=6e5116da; ver=7.0; loginfrom=null\" cookies = &#123;i.split(\"=\")[0]:i.split(\"=\")[1] for i in cookies.split(\"; \")&#125; yield scrapy.Request( self.start_urls[0], callback=self.parse, cookies=cookies )","permalink":"https://codermino.github.io/2020/07/26/scrapy%E6%B7%BB%E5%8A%A0cookie%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F/","photos":[]},{"tags":[{"name":"scrapy爬虫细节","slug":"scrapy爬虫细节","permalink":"https://codermino.github.io/tags/scrapy%E7%88%AC%E8%99%AB%E7%BB%86%E8%8A%82/"}],"title":"scrapy爬虫细节","date":"2020/07/25","text":"scrapy.Request相关 yield scrapy.Request( url, callback, meta = &#123;\"item\":item&#125; ) 在对应的callback函数中可以使用下面的代码，接收上一个函数传递过来的参数。 item=response.meta['key'] 使用for...in 循环导致数据重复问题 在scrapy中使用了for in 循环，由于是多线程，如果还需要继续scrapy.Request进行请求更深的页面数据。 可以使用form copy import deepcopy 进行深拷贝。 可以防止scrapy多线程导致item的数据重复(上一个数据传递过来之后，后面的数据还没有解析完成， 下一个for循环，将传递下去的item的某些字段覆盖，从而可能导致重复) scrapy翻页 response.text =&gt; unicode编码返回body部分，等同于 response.body.decode(response.encoding) page_count = int(re. findall(\"var pagecount=.7);, response.body.decode())[0]) current_page = int(re. findall\"var currentPage=.2);, response.body.decode())[0] if current_page page_count: next_url item[\"s_href\"] +\"?pageNumber=[&amp;sort=\". format(current_page 1) yield scrapy. Request( next_url, callback=self.parse_book_list, meta = &#123;\"item\":response.meta[\"item\"]&#125; ) 创建CrawlSpider爬虫简要步骤 1.创建项目文件： scrapy startproject douyu 2.进入项目文件： cd douyu 3.创建爬虫 scrapy genspider -t crawl dy 'douyu.com' 正则的使用 def parse_item(self, response): item = &#123;&#125; item[\"title\"]=re.findall(\"&lt;!---TitleStart--&gt;(.*)&lt;--TitleEnd---&gt;\", response.body. decode())[0] item[\"publish_date\"] = re.findall(\"发布时间:(20\\d&#123;2&#125;-\\d&#123;2&#125;-\\d&#123;2&#125;)\", response.body. decode())[0] CrawlSpider补充知识 CrawlSpider补充(了解) LinkExtractor更多常见参数: allow:满足括号中“正则表达式的URL会被提取,如果为空,则全部匹配。 (就是在当前的爬虫的页面，如果为True就会寻找当前页面是否有满足当前rule的连接，如果为False就不会继续寻找) deny:满足括号中“正则表达式\"的URL一定不提取(优先级高于 allow) allow_domains:会被提取的链接的 domains. deny_domains:一定不会被提取链接的 domains restrict_xpaths:使用 xpath表达式和 allow共同作用过滤链接,级 xpath足范围内的ur地址会被提取 spiders.rule常见参数: linkextractor:是一个 Link Extractor对象,用于定义需要提取的链接。 calLback:从linkextractor中每获取到链接时,参数所指定的值作为回调函数 follow:是一个布尔(boolean)值,指定了根据该规则从 response提取的链接是否需要跟进。 如果 callback为none, follow默认设置为Tre,否则默认为 False process_links:指定该 spider中哪个的函数将会被调用,从 linkextractor中获取到链接列表时将会调用该函数, 该方法主要用来过滤url process_request:指定该 spider中哪个的函数将会被调用,该规则提取到每个 request时都会调用该函数, 用来过滤 request 模拟登录的原因 scrapy模拟登陆 为什么需要模拟登陆? 获取 cookie,能够爬取登陆后的页面 回顾: requests是如何模拟登陆的? 1、直接携带 cookies请求页面 2、找接口发送post请求 cookie存储 selenium是如何模拟登陆的? 找到对应的 input标签,输入文字点击登录 dir函数的使用 在python2.7中, dir(response)查看response内置函数可以找到decode, encode()方法。 class CheckUserAgent: def process_response(self, request, response, spider): print(dir(response)) print(request.headers[User-Agent\"]) 添加代理 class RandomUserAgent(object): def process_request(self, request, spider): useragent= random.choice(UER_AGENTS) request.headers[\"User-Agent\"] = useragent #添加自定义的UA,给 requestheaders的赋值即可 class ProxyMiddleware(object) def process_request(self, request, spider): reqeust.meta [\"proxy\"] = \"http://124.115.126.76: 808\" #添加代理,需要在request的mea信息中添加字段 #代理的形式为:协议+ip地址+端口 发送post请求 使用scrapr.Request的时候一直是发送的get请求， 那么post请求就是需要使用scrapy.FormRequest来发送， 同时使用formdata来携带需要post的数据 scrapy模拟登陆之发送post请求 class GithubSpider(scrapy.Spider): name =github' allowed_domains ['github.com'] start_urls = ['https://github.com/login' -请求首页,为了获取登录参数 headers =&#123; \"Accept\":\"**\", \"Accept-Language\": \"en-US, en;q=. 8, zh-TW;q=0.6, zh; q=0.4\", &#125; def parse(self, response): print(response.url) utf8 = response.xpath(\"//form[@action='/session']/div[1]/input[1]/@value\").extract_first() authenticity_token = response.xpath(\"//form[@action='/session']/div[1]/input[2]/@value\").extract_first() return scrapy.FormRequest( \"https://github.com/session\", headers=self.headers, #可以在spider中定义,也可以在 setting中定义 formdata = dict( commit=\"Sign in\", utf8=utf8, authenticity_token=authenticity_token, login=\"user_name\",(对应的标签的name) password=\"password\"(对应的标签的name) ), callbackself = self.after_login #登录之后的回调函数 ) def after_login(self, response): print(response.url,\"*\"*100, response.status) 注意 : github的部分页面只允许一处登录,比如https:/github.comsettings/security 自动寻找post的action进行提交 import scrapy import re class Github2Spider(scrapy.Spider): name =github2' allowed_domains ['github.com'] start_urls =['https://github.com/login'] def parse(self, response): yield scrapy.FormRequest.from_response( response, #自动的从response中寻找from表单 formdata = &#123;\"login\":\"noobpythoner\",\"password\":\"zhoudawei1123\"&#125;, callback=self.after_login ) def after_login(self, response): print(re.findall(\"noobpythoner|NoobPythoner\", response.body.decode())) xpath的contains语法 div_list = response.xpath(\"//div[contains(@class,'i')]) 提取下一页的文本 next_url = response.xpath(\"//a[text()='下一页']/@href).extract_first() if next_url is not None: next_url = urllib","permalink":"https://codermino.github.io/2020/07/25/scrapy%E7%88%AC%E8%99%AB%E7%BB%86%E8%8A%82/","photos":[]},{"tags":[{"name":"Excel打开UTF8编码CSV文件乱码","slug":"Excel打开UTF8编码CSV文件乱码","permalink":"https://codermino.github.io/tags/Excel%E6%89%93%E5%BC%80UTF8%E7%BC%96%E7%A0%81CSV%E6%96%87%E4%BB%B6%E4%B9%B1%E7%A0%81/"}],"title":"Excel打开UTF8编码CSV文件乱码","date":"2020/07/25","text":"1. 新建一个excel表格 2. 执行“数据”-&gt;“自文本” 3. 选择 CSV 文件，出现文本导入向导 4. 选择“分隔符号”，下一步 5. 勾选“逗号”，去掉“ Tab 键”，下一步，完成 6. 在“导入数据”对话框里，直接点确定","permalink":"https://codermino.github.io/2020/07/25/Excel%E6%89%93%E5%BC%80UTF8%E7%BC%96%E7%A0%81CSV%E6%96%87%E4%BB%B6%E4%B9%B1%E7%A0%81/","photos":[]},{"tags":[{"name":"scrapy保存图片","slug":"scrapy保存图片","permalink":"https://codermino.github.io/tags/scrapy%E4%BF%9D%E5%AD%98%E5%9B%BE%E7%89%87/"}],"title":"scrapy保存图片","date":"2020/07/12","text":"为什么使用ImagesPipelines进行图片下载 1. 避免重新下载最近已经下载过的数据 2. 可以方便的指定文件存储的路径 3. 可以将下载的图片转换成通用的格式。比如png或jpg 4. 可以方便的成成缩略图 5. 可以方便的检测图片的宽和高，确保他们满足最小限制 6. 异步下载，效率非常高 crawl.py文件内容 import scrapy from bmw.items import BmwItem #引入item文件的BmwItem类 class Bmw5Spider(scrapy.Spider): name = 'bmw5' start_urls = ['https://car.autohome.com.cn/pic/series/4350.html'] def parse(self, response): uiboxs=response.xpath(\"//div[@class='uibox']\")[1:] for uibox in uiboxs: title=uibox.xpath(\".//div[@class='uibox-title']/a/text()\").get() #获取分类的标题 images=uibox.xpath(\".//ul/li/a/img/@src\").getall() #获取所有图片的url地址 urls=list(map(lambda url:response.urljoin(url),images)) #将图片的url地址进行处理，前面加上https:// item=BmwItem(title=title,image_urls=urls) #进行包装 yield item #返回给items.py文件 items.py文件内容 import scrapy class BmwItem(scrapy.Item): title=scrapy.Field() #用来存储图片分类的名称标题 image_urls=scrapy.Field() #用来存储需要下载的图片的url images=scrapy.Field() #用来保存下载之后图片的本地路径 方法一、同步的方式进行图片下载 这样下载的方式是一个一个的下载，下载的效率比较低， 同步的方式进行下载 import os from urllib import request class BmwPipeline(object): def __init__(self): #os.path.dirname(__file__)获得当前文件所在的上级目录 #创建项目工程下的iamges文件夹 self.path=os.path.join(os.path.dirname(os.path.dirname(__file__)),'images') #判断images文件夹是否存在，如果不存在则创建 if not os.path.exists(self.path): os.mkdir(self.path) #这个函数会自动调用,每次爬取一个item就会调用一次进行数据的处理 def process_item(self, item, spider): title=item['title'] #图片所在分类的标题 urls=item['image_urls'] #分类下图片的url地址 category_path=os.path.join(self.path,title) #创建分类文件夹 if not os.path.exists(category_path): os.mkdir(category_path) #遍历urls数组，进行图片下载 for url in urls: image_name=url.split('_')[-1] #按照_进行拆分得到图片的名称 request.urlretrieve(url,os.path.join(category_path,image_name)) #进行图片的下载 return item 对应的settings.py文件内容 ITEM_PIPELINES = &#123; 'bmw.pipelines.BmwPipeline': 300, #开启pipelines &#125; 方法二、使用scrapy自带的ImagesPipeline settings.py文件的内容 IMAGES_EXPIRES = 90 # 90天内抓取的都不会被重抓 ITEM_PIPELINES = &#123; 'scrapy.pipelines.images.ImagesPipeline': 1, &#125; 方法三、重写ImagesPipeline---Demo1 import os from urllib import request from scrapy.pipelines.images import ImagesPipeline from bmw import settings #继承了ImagesPipeline这个类 class BMWImagePipeline(ImagesPipeline): def get_media_requests(self, item, info): #这个方法是在发送下载请求之前调用 #其实这个方法本身就是去发送下载请求的 request_objs=super(BMWImagePipeline, self).get_media_requests(item,info) for request_obj in request_objs: request_obj.item=item return request_objs # 我们可以通过继承FilesPipeline重写file_path() # 方法来重定义文件名 def file_path(self, request, response=None, info=None): #这个方法是在图片将要被存储的时候调用的，来获取这个图片存储的路径 path=super(BMWImagePipeline, self).file_path(request,response,info) category=request.item.get('title') image_store=settings.IMAGES_STORE category_path=os.path.join(image_store,category) if not os.path.exists(category_path): os.mkdir(category_path) image_name=path.replace(\"full/\",'') image_path=os.path.join(category_path,image_name) return image_path def item_completed(self, results, item, info): \"\"\" 将图片的本地路径赋值给item['image_paths'] :param results:下载结果，二元组定义如下：(success, image_info_or_failure)。 第一个元素表示图片是否下载成功；第二个元素是一个字典。 如果success=true，image_info_or_error词典包含以下键值对。失败则包含一些出错信息。 字典内包含* url：原始URL * path：本地存储路径 * checksum：校验码 :param item: :param info: :return: \"\"\" # print(results) image_paths = [x['path'] for ok, x in results if ok] if not image_paths: raise DropItem(\"Item contains no images\") # 如果没有路径则抛出异常 item['images'] = image_paths return item 方法三、重写ImagesPipeline---Demo2 #引入其他所需的相关模块 from scrapy import Request from scrapy.exceptions import DropItem category = '' #继承了ImagesPipeline这个类 class BMWImagePipeline(ImagesPipeline): global category #用来存储下载的图片所属的分类标题 category = item['title'] for img_url in item['image_urls']: #遍历image_urls并发起请求 yield Request(img_url) # 我们可以通过继承FilesPipeline重写file_path() # 方法来重定义文件名 def file_path(self, request, response=None, info=None): image_store=settings.IMAGES_STORE #获取settings.py中配置的图片下载路径 category_path=os.path.join(image_store,category) #创建分类名称文件夹 if not os.path.exists(category_path): #不存在则进行创建 os.mkdir(category_path) image_name = request.url.split(\"__\")[-1] #将图片的url地址按照_进行拆分得到图片的名称 return os.path.join(category_path,image_name) #拼接下载的图片的路径 def item_completed(self, results, item, info): \"\"\" 将图片的本地路径赋值给item['image_paths'] :param results:下载结果，二元组定义如下：(success, image_info_or_failure)。 第一个元素表示图片是否下载成功；第二个元素是一个字典。 如果success=true，image_info_or_error词典包含以下键值对。失败则包含一些出错信息。 字典内包含* url：原始URL * path：本地存储路径 * checksum：校验码 :param item: :param info: :return: \"\"\" # print(results) #results 数组第一个参数为表示图片是否下载成功；第二个元素是一个字典。 #ok, x in results 遍历results数组 if ok 成立 去除x['path']并且包装成数组返回给image_paths image_paths = [x['path'] for ok, x in results if ok] if not image_paths: raise DropItem(\"Item contains no images\") # 如果没有路径则抛出异常 item['images'] = image_paths #将下载之后的图片的本地路径保存在items.py的images中 #也可以在这里使用os.rename进行文件的重命名 return item Demo2对应的settings.py文件配置 #设置图片的存储路径 IMAGES_STORE=os.path.join(os.path.dirname(os.path.dirname(__file__)),'images4') #90天内抓取的都不会被重抓 IMAGES_EXPIRES = 90 #90天内抓取的都不会被重抓 ITEM_PIPELINES = &#123; 'bmw.pipelines.BMWImagePipeline':1 &#125; ImagesPipelines的其他作用---保存缩略图 settings.py文件的相关配置 # 设置图片缩略图 IMAGES_THUMBS = &#123; 'small': (50, 50), 'big': (250, 250), &#125; # 图片过滤器，最小高度和宽度，低于此尺寸不下载 # 注意：这些尺寸的限制不会影响缩略图生成 # 默认情况下，没有限制，所有的图片都会被处理。 IMAGES_MIN_HEIGHT = 70 IMAGES_MIN_WIDTH = 70 piplines文件内容---更改thumbs缩略图保存的文件路径 def thumb_path(self, request, thumb_id, response=None, info=None): ## start of deprecation warning block (can be removed in the future) def _warn(): from scrapy.exceptions import ScrapyDeprecationWarning import warnings warnings.warn('ImagesPipeline.thumb_key(url) method is deprecated, please use ' 'thumb_path(request, thumb_id, response=None, info=None) instead', category=ScrapyDeprecationWarning, stacklevel=1) # check if called from thumb_key with url as first argument if not isinstance(request, Request): _warn() url = request else: url = request.url # detect if thumb_key() method has been overridden if not hasattr(self.thumb_key, '_base'): _warn() return self.thumb_key(url, thumb_id) ## end of deprecation warning block thumb_guid = hashlib.sha1(to_bytes(url)).hexdigest() # change to request.url after deprecation return 'thumbs/%s/%s/%s.jpg' % (category,thumb_id, thumb_guid)","permalink":"https://codermino.github.io/2020/07/12/scrapy%E4%BF%9D%E5%AD%98%E5%9B%BE%E7%89%87/","photos":[]},{"tags":[{"name":"scrapy数据保存为xml格式","slug":"scrapy数据保存为xml格式","permalink":"https://codermino.github.io/tags/scrapy%E6%95%B0%E6%8D%AE%E4%BF%9D%E5%AD%98%E4%B8%BAxml%E6%A0%BC%E5%BC%8F/"}],"title":"scrapy数据存为xml格式","date":"2020/07/12","text":"scrapy crawl myspider -o data.xml","permalink":"https://codermino.github.io/2020/07/12/scrapy%E6%95%B0%E6%8D%AE%E5%AD%98%E4%B8%BAxml%E6%A0%BC%E5%BC%8F/","photos":[]},{"tags":[{"name":"scrapy数据存入csv文件","slug":"scrapy数据存入csv文件","permalink":"https://codermino.github.io/tags/scrapy%E6%95%B0%E6%8D%AE%E5%AD%98%E5%85%A5csv%E6%96%87%E4%BB%B6/"}],"title":"scrapy数据存入csv文件","date":"2020/07/11","text":"方法一、通过终端方式 scrapy crawl name(爬虫名字) -o result.csv tip: #在pycharm中可以新建一个start.py加入如下内容，然后运行即可 from scrapy import cmdline cmdline.execute(\"scrapy crawl field(爬虫名字) -o info.csv -t csv\".split()) 方法一、通过pipelines方式 from scrapy.exporters import CsvItemExporter class CsvPipeline（object）： def __init __（self）： self.file = open（“xxx.csv”，'wb'） self.exporter = CsvItemExporter（self.file， encoding='utf-8'） self.exporter.start_exporting（） def close_spider（ self，spider）： self.exporter.finish_exporting（） self.file.close（） def process_item（self，item，spider）： self.exporter.export_item（item） return item Demo2--pipelines方式 import csv class MyProjectPipeline(object): # 保存为csv格式 def __init__(self): # 打开文件，指定方式为写，利用第3个参数把csv写数据时产生的空行消除 self.f = open(\"myproject.csv\",\"a\",newline=\"\") # 设置文件第一行的字段名，注意要跟spider传过来的字典key名称相同 self.fieldnames = [\"goods_sketch\",\"goods_img\",\"good_price\",\"goods_shop\",\"b_href\",\"title\"] # 指定文件的写入方式为csv字典写入，参数1为指定具体文件，参数2为指定字段名 self.writer = csv.DictWriter(self.f, fieldnames=self.fieldnames) # 写入第一行字段名，因为只要写入一次，所以文件放在__init__里面 self.writer.writeheader() def process_item(self, item, spider): # 写入spider传过来的具体数值 self.writer.writerow(item) # 写入完返回 return item def close(self,spider): self.f.close()","permalink":"https://codermino.github.io/2020/07/11/scrapy%E6%95%B0%E6%8D%AE%E5%AD%98%E5%85%A5csv%E6%96%87%E4%BB%B6/","photos":[]},{"tags":[{"name":"scrapy数据存入json文件","slug":"scrapy数据存入json文件","permalink":"https://codermino.github.io/tags/scrapy%E6%95%B0%E6%8D%AE%E5%AD%98%E5%85%A5json%E6%96%87%E4%BB%B6/"}],"title":"scrapy数据写入json文件","date":"2020/07/11","text":"方法一、使用终端命令 scrapy crawl novel -o novel.json 方法二、使用pipelines from scrapy.exporters import JsonItemExporter # JsonItemExporter：一次性写入大量数据，占用内存 from scrapy.exporters import JsonLinesItemExporter # 逐条写入 class JsonPipeline(object): def __init__(self): self.fp = open('sftaobao.json', 'wb') # ensure_ascii=False:以中文字符保存 self.exporter = JsonItemExporter(self.fp, ensure_ascii=False, encoding='utf-8') # JsonLinesItemExporter：一个字典一行，整个文件不满足json格式的；数据都直接存到磁盘文件中，内存占用少. # self.exporter = JsonLinesItemExporter(self.fp, ensure_ascii=False, encoding='utf-8') #不需要start_exporting和finish_exporting self.exporter.start_exporting() # 以标识 exporting 过程的开始。 def open_sprider(self): pass def process_item(self, item, spider): self.exporter.export_item(item) return item def close_sprider(self, spider): self.exporter.finish_exporting() # 以标识 exporting 过程的结束 self.fp.close() 方法三、文件读写方式 import json class JsonWriterPipeline(object): def open_spider(self, spider): #在爬虫开启的时候执行,仅执行一次 self. file =open(spider. settings.get( \"SAVE_FILE\", \"./temp.json\"), 'w') def close_spider(self, spider): #在爬虫关闭的时候执行,仅执行一次 self.file.close() def process_item(self, item, spider): line=json. dumps(dict(item))+\"\\n\" self.file.write(line) return item #不return的情况下,另个一个权重较低的 pipeline就不会获取到该item","permalink":"https://codermino.github.io/2020/07/11/scrapy%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5json%E6%96%87%E4%BB%B6/","photos":[]},{"tags":[{"name":"scrapy数据存入redis","slug":"scrapy数据存入redis","permalink":"https://codermino.github.io/tags/scrapy%E6%95%B0%E6%8D%AE%E5%AD%98%E5%85%A5redis/"}],"title":"scrapy数据存入redis","date":"2020/07/11","text":"import redis class QiubaiproPipelineByRedis(object): conn = None def open_spider(self,spider): print('开始爬虫') # 创建链接对象 self.conn = redis.Redis(host='127.0.0.1',port=6379) def process_item(self, item, spider): dict = &#123; 'author':item['author'], 'content':item['content'] &#125; # 写入redis中 self.conn.lpush('data', dict) return item from scrapy.exceptions import DropItem def process_item(self, item, spider): #当添加失败的时候会返回一个0 if self.conn.sadd('data',item['author']) return item #丢掉不符合条件的item raise DropItem","permalink":"https://codermino.github.io/2020/07/11/scrapy%E6%95%B0%E6%8D%AE%E5%AD%98%E5%85%A5redis/","photos":[]},{"tags":[{"name":"scrapy数据存入mongodb","slug":"scrapy数据存入mongodb","permalink":"https://codermino.github.io/tags/scrapy%E6%95%B0%E6%8D%AE%E5%AD%98%E5%85%A5mongodb/"}],"title":"scrapy数据存入mongodb","date":"2020/07/11","text":"存入mongodb def __init__(self): host = settings['MONGODB_HOST'] #数据库的host 如:127.0.0.1 port = settings['MONGODB_PORT'] #数据库端口号 如：27017 dbname = settings['MONGODB_DBNAME'] #数据库名称 如:XXX # 创建数据库连接 client = pymongo.MongoClient(host=host, port=port) # 指向指定数据库 mdb = client[dbname] # 获取数据库里面存放数据的表名 self.post = mdb[settings['MONGODB_DOCNAME']] def process_item(self, item, spider): data = dict(item) # 向指定的表里添加数据 self.post.insert(data) return item Demo2 from pymongo import MongoClient class xxxPipeline(object): def open_spider(self,spider): client = MongoClient() self.collection = client['test']['test'] def process_item(self,item,spider): spider.setting,get('MONGO_HOST') item['content'] = self.process_content(item['content']) print(item) return item def process_content(self,content): content = [re.sub(r\"\\xa0|\\s\",\"\",i) for i in content] content = [i for i in content if len(i)&gt;0] #去除列表中的空字符串 return content","permalink":"https://codermino.github.io/2020/07/11/scrapy%E6%95%B0%E6%8D%AE%E5%AD%98%E5%85%A5mongodb/","photos":[]},{"tags":[{"name":"scrapy数据存入mysql","slug":"scrapy数据存入mysql","permalink":"https://codermino.github.io/tags/scrapy%E6%95%B0%E6%8D%AE%E5%AD%98%E5%85%A5mysql/"}],"title":"scrapy数据存入mysql","date":"2020/07/11","text":"1、同步方式 import pymysql #引入相关库 class MysqlPipeline(object): \"\"\" 同步操作 \"\"\" def __init__(self): # 建立连接,下面是两种方式 1. self.conn = pymysql.connect( host='localhost', db='bole', user='root', passwd='123456', charset='utf8', port=330, use_unicode=True) 2. self.conn = pymysql.connect('localhost','root','Abcd1234','test') # 有中文要存入数据库的话要加charset='utf8' # 创建游标 self.cursor = self.conn.cursor() #每爬取到一条数据就会调用一次process_item函数 def process_item(self,item,spider): # sql语句 try: # 查重处理,根据表的主键进行一次查询，查看是否有重复数据 self.cursor.execute( \"\"\"select * from doubanmovie where img_url = %s\"\"\", item['img_url']) # 是否有重复数据 repetition = self.cursor.fetchone() if repetition: #两种方式丢弃无效数据 1. pass 2. raise DropItem(\"Missing price in %s\" % item) #需要引入相关的模块from scrapy.exceptions import DropItem else: insert_sql = \"\"\" insert into test_zxf(quote,author,tags,born_date,born_location) VALUES(%s,%s,%s,%s,%s) \"\"\" # 执行插入数据到数据库操作 self.cursor.execute(insert_sql,(item['quote'],item['author'],item['tags'],item['born_date'], item['born_location'])) # 提交，不进行提交无法保存到数据库 self.conn.commit() except Exception as error: # 出现错误时打印错误日志 self.conn.rollback() log(error) return item def close_spider(self,spider): # 关闭游标和连接 self.cursor.close() self.conn.close() 同步方式Demo2 class WhfjPipeline(object): def __init__(self): dbparams = &#123; 'host': '127.0.0.1', 'user': 'root', 'password': '19980211', 'database': 'fangjia', 'port': 3306, 'charset': 'utf8' &#125; self.conn = pymysql.connect(**dbparams) self.cursor = self.conn.cursor() self._sql = None def process_item(self, item, spider): self.cursor.execute(self.sql, (item['xiaoqu_name'], item['position'], item['price'])) self.conn.commit() return item #将一个方法变为属性进行调用 @property def sql(self): if not self._sql: self._sql = \"\"\" insert into fangchan2(id,xiaoqu_name,position,price) values(null,%s,%s,%s); \"\"\" return self._sql return self._sql tip: ### # 我们可以使用@property装饰器来创建只读属性，@property装饰器会将方法转换为相同名称的只读属性,可以与所定义的属性配合使用，这样可以防止属性被修改。 # class DataSet(object): # @property # def method_with_property(self): ##含有@property # return 15 # def method_without_property(self): ##不含@property # return 15 # # l = DataSet() # print(l.method_with_property) # 加了@property后，可以用调用属性的形式来调用方法,后面不需要加（）。 # print(l.method_without_property()) #没有加@property , 必须使用正常的调用方法的形式，即在后面加() ### 1、异步方式 #piplines调用 from scrapyDemo.db.dbhelper import DBHelper class ScrapydemoPipeline(object): # 连接数据库 def __init__(self): self.db = DBHelper() def process_item(self, item, spider): # 插入数据库 self.db.insert(item) return item #这里面我们用到了数据库的操作DBHelper类，那 #么我们在scrapyDemo/db目录下创建dbhelper.py 模块，记得再创建一个__init__.py哦。 import pymysql from twisted.enterprise import adbapi from scrapy.utils.project import get_project_settings #导入seetings配置 import time class DBHelper(): '''这个类也是读取settings中的配置，自行修改代码进行操作''' def __init__(self): settings = get_project_settings() #获取settings配置，设置需要的信息 #或者使用这种方式来获取settings中定义的变量 userAgent = settings.get('USER_AGENT') dbparams = dict( host=settings['MYSQL_HOST'], #读取settings中的配置 db=settings['MYSQL_DBNAME'], user=settings['MYSQL_USER'], passwd=settings['MYSQL_PASSWD'], charset='utf8', #编码要加上，否则可能出现中文乱码问题 cursorclass=pymysql.cursors.DictCursor, use_unicode=False, ) #**表示将字典扩展为关键字参数,相当于host=xxx,db=yyy.... dbpool = adbapi.ConnectionPool('pymysql', **dbparams) self.dbpool = dbpool def connect(self): return self.dbpool #创建数据库 def insert(self, item): sql = \"insert into tech_courses(title,image,brief,course_url,created_at) values(%s,%s,%s,%s,%s)\" #调用插入的方法 query = self.dbpool.runInteraction(self._conditional_insert, sql, item) #调用异常处理方法 query.addErrback(self._handle_error) return item #写入数据库中 def _conditional_insert(self, tx, sql, item): item['created_at'] = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())) params = (item[\"title\"], item['image'], item['brief'], item['course_url'], item['created_at']) tx.execute(sql, params) #错误处理方法 def _handle_error(self, failue): print('--------------database operation exception!!-----------------') print(failue) #demo2: #tip: 1. @classmethod不需要self参数，但第一个参数需要是表示自身类的cls参数。 # 用twisted库将数据进行异步插入到数据库 class MysqlTwistedPipeline(object): def __init__(self, dbpool): self.dbpool = dbpool #这个函数会自动调用 @classmethod def from_settings(cls, settings): # 需要在setting中设置数据库配置参数 dbparms = dict( host=settings['MYSQL_HOST'], db=settings['MYSQL_DBNAME'], user=settings['MYSQL_USER'], passwd=settings['MYSQL_PASSWORD'], charset='utf8', cursorclass=MySQLdb.cursors.DictCursor, use_unicode=True, ) # 连接ConnectionPool（使用MySQLdb连接，或者pymysql） dbpool = adbapi.ConnectionPool(\"pymysql\", **dbparms) # **让参数变成可变化参数 return cls(dbpool) # # 返回一个pipeline实例化对象 def process_item(self, item, spider): # 使用twisted将MySQL插入变成异步执行 #使用数据库连接池对象进行数据库操作,自动传递cursor对象到数据库操作方法的第一个参数 query = self.dbpool.runInteraction(self.do_insert, item) # 添加异常处理 query.addCallback(self.handle_error) def handle_error(self, failure): # 处理异步插入时的异常 print(failure) def do_insert(self, cursor, item): # 执行具体的插入 insert_sql = \"\"\" insert into jobbole_artitle(name, base_url, date, comment) VALUES (%s, %s, %s, %s) \"\"\" #这里不需要进行commit()提交，adbapi会进行自动的commit cursor.execute(insert_sql, (item['name'], item['base_url'], item['date'], item['coment'],)) 最后的tip: 在python1.7以前的版本引入settings中定义的常量的方式可以使用: from scrapy.conf import settings 但是在1.7版本之后,scrapy.conf就被移除了，1.7以后的版本里，正确使用 settings.py中配置的方法是: from scrapy.utils.project import get_project_settings settings = get_project_settings() host = settings['MONGODB_HOST] port = settings['MONGODB_PORT']","permalink":"https://codermino.github.io/2020/07/11/scrapy%E6%95%B0%E6%8D%AE%E5%AD%98%E5%85%A5mysql/","photos":[]},{"tags":[{"name":"markdown基本语法","slug":"markdown基本语法","permalink":"https://codermino.github.io/tags/markdown%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95/"}],"title":"markdown基本语法","date":"2020/07/11","text":"+ space = 原点 数字+.+space=有序列表 #+space一级标题 ##+space二级标题 **字符**加粗 *字符*斜体 &gt;+space说明文字 ```+语言=代码块 内容原封不动的显示使用` 超链接 [百度](https://www.baidu.com)","permalink":"https://codermino.github.io/2020/07/11/markdown%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95/","photos":[]},{"tags":[{"name":"python引入模块的四种方式","slug":"python引入模块的四种方式","permalink":"https://codermino.github.io/tags/python%E5%BC%95%E5%85%A5%E6%A8%A1%E5%9D%97%E7%9A%84%E5%9B%9B%E7%A7%8D%E6%96%B9%E5%BC%8F/"}],"title":"python引入模块四种方式","date":"2020/07/11","text":"1. import time #使用import模块名直接导入一个模块 2. from random import randint #from模块名 import函数名,导入一个模块里的方法或者变量 3. from math import* #from模块名 import*导入这个模块里的\"所有方法和变量 4. import datetime as dt #导入一个模块并给这个模块起一个别名 5. from copy import deepcopy as dp #from模块名 import函数名as别名","permalink":"https://codermino.github.io/2020/07/11/python%E5%BC%95%E5%85%A5%E6%A8%A1%E5%9D%97%E5%9B%9B%E7%A7%8D%E6%96%B9%E5%BC%8F/","photos":[]},{"tags":[{"name":"python字符串前修饰符","slug":"python字符串前修饰符","permalink":"https://codermino.github.io/tags/python%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%89%8D%E4%BF%AE%E9%A5%B0%E7%AC%A6/"}],"title":"python字符串前修饰符","date":"2020/07/05","text":"1、字符串前加 u 例：u\"我是含有中文字符组成的字符串。\" 作用： 后面字符串以 Unicode 格式 进行编码，一般用在中文字符串前面，防止因为源码储存格式问题，导致再次使用时出现乱码。 2、字符串前加 r 例：r\"\\n\\n\\n\\n” # 表示一个普通生字符串 \\n\\n\\n\\n，而不表示换行了。 作用： 去掉反斜杠的转移机制。 （特殊字符：即那些，反斜杠加上对应字母，表示对应的特殊含义的，比如最常见的”\\n”表示换行，”\\t”表示Tab等。 ） 应用： 常用于正则表达式，对应着re模块。 3、字符串前加 b 例: response = b'Hello World!' # b' ' 表示这是一个 bytes 对象 作用： b\" \"前缀表示：后面字符串是bytes 类型。 用处： 网络编程中，服务器和浏览器只认bytes 类型数据。 如：send 函数的参数和 recv 函数的返回值都是 bytes 类型 附： 在 Python3 中，bytes 和 str 的互相转换方式是 str.encode('utf-8') bytes.decode('utf-8') 具体见底部代码 python str与bytes之间的转换 4、字符串前加 f import time t0 = time.time() time.sleep(1) name = 'processing' # 以 f开头表示在字符串内支持大括号内的python 表达式 print(f'{name} done in {time.time() - t0:.2f} s') 输出： processing done in 1.00 s # bytes object b = b\"example\" # str object s = \"example\" # str to bytes sb = bytes(s, encoding = \"utf8\") # bytes to str bs = str(b, encoding = \"utf8\") # an alternative method # str to bytes sb2 = str.encode(s) # bytes to str bs2 = bytes.decode(b)","permalink":"https://codermino.github.io/2020/07/05/python%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%89%8D%E4%BF%AE%E9%A5%B0%E7%AC%A6/","photos":[]},{"tags":[{"name":"pyinstaller","slug":"pyinstaller","permalink":"https://codermino.github.io/tags/pyinstaller/"}],"title":"pyinstaller的使用","date":"2020/07/05","text":"pyinstaller -F -w TestDataGen.py pyinstaller -Fw -i xxx.ico TestDataGen.py","permalink":"https://codermino.github.io/2020/07/05/pyinstaller%E7%9A%84%E4%BD%BF%E7%94%A8/","photos":[]},{"tags":[{"name":"git","slug":"git","permalink":"https://codermino.github.io/tags/git/"}],"title":"git提交pr","date":"2020/07/05","text":"简单过程 首先git分为本地仓库(自己电脑中)和远程仓库(git官网自己的账号中)，仓库可以理解为保存代码的地方， 简单的说是在自己本地仓库修改代码，提交到自己远程仓库，提交pr后被接受后再会被合并到master。 下面一步一步来。 详细过程 申请账号、添加ssh公钥等过程就不说了哈。 fork 将项目fork到自己的仓库中，可以在github的首页搜索到自己的想要的开源项目， 我以flink为例： 进去后，点出fork，稍等片刻，此项目便会出现在自己的仓库中 进到自己fork的项目中，就能看到Clone or download按钮，如下，记下这个https链接。 通过上面的步骤，已经将远程仓库建好 clone 需要将远程仓库clone到本地，此处省略安装本地github的过程， 随便在哪个目录(项目存放的目录)，右键打开一个Git base， 执行一下git clone https://github.com/***/***.git(使用上一步的https链接)， 等待命令完成，时间视下载速度而定，也许会比较慢， 网上也有些可以提高git clone速度的方法，不防一试。 上面的命令完成后，当前目录下会多一个目录，我clone的是flink， 所以会多一个flink目录，进到flink目录中，试试跑一下git status试试，会提示现在是master分支。 用git remote -v命令，可以看到此时只与自己的远程仓库建立了连接 还需要与上游建立连接，这里上游指的是一开始fork的那个项目源，以flink为例，执行如下命令： git remote add upstream https://github.com/apache/flink.git 再用git remote -v可以看到： 接下来就能创建分支了。 创建分支 接着上面的运行命令：git checkout -b flink-fs， 这个命令的意思是创建一个叫flink-fs的分支，运行这个命令后bash将自动切换到新的分支下. 修改代码 自行修改代码. 提交 可以先使用git status来查看有哪些文件被修改了 然后再git add ***.java将要提交的文件都加上 然后再git commit -m \"modify XX\"，需要注意的是git commit只是把修改的代码提交到当前分支(当前分支是flink-fs，而不是master)，”modify XX”是本次提交的简单说明 然后再git push origin flink-fs，这一步才是将当前分支推送到自己的远程仓库。 这时，在自己的远程仓库便能看刚才push上去的分支了 提交pr 找到New pull request 需要注意的是compare处选择刚才提交上来的分支 然后点Create pull request 写好名字，写好说明，提交，就OK啦。","permalink":"https://codermino.github.io/2020/07/05/git%E6%8F%90%E4%BA%A4pr/","photos":[]},{"tags":[{"name":"git","slug":"git","permalink":"https://codermino.github.io/tags/git/"}],"title":"git同步更新fork项目","date":"2020/07/05","text":"master:git同步更新fork项目 1、打开fork 过来的项目如下所示： 2、点击new pull request 3、在进入的界面， 后进行将左边的设置为你自己的仓库， fork 过来的源在右边， 如下图： 4、当选择完后会变成下图（关键步骤，千万不可选错分支） 5、接下来， 将其展示出可以调整状态： 右边改为源fork地址 6、就会出现变更数据： 7、点击create pull request 8、进行数据的合并： 9 、最后合并!","permalink":"https://codermino.github.io/2020/07/05/git%E5%90%8C%E6%AD%A5%E6%9B%B4%E6%96%B0fork%E9%A1%B9%E7%9B%AE/","photos":[]},{"tags":[{"name":"cookie和session的区别","slug":"cookie和session的区别","permalink":"https://codermino.github.io/tags/cookie%E5%92%8Csession%E7%9A%84%E5%8C%BA%E5%88%AB/"}],"title":"cookie和session的区别","date":"2020/06/25","text":"cookie 和session 的区别详解 这些都是基础知识，不过有必要做深入了解。 先简单介绍一下。二者的定义：当你在浏览网站的时候，WEB 服务器会先送一小小资料放在你的计算机上， Cookie 会帮你在网站上所打的文字或是一些选择，都纪录下来。 当下次你再光临同一个网站，WEB 服务器会先看看有没有它上次留下的 Cookie 资料， 有的话，就会依据 Cookie里的内容来判断使用者，送出特定的网页内容给你。 Cookie 的使用很普遍，许多有提供个人化服务的网站，都是利用 Cookie来辨认使用者， 以方便送出使用者量身定做的内容，像是 Web 接口的免费 email 网站，都要用到 Cookie。 具体来说cookie机制采用的是在客户端保持状态的方案， 而session机制采用的是在服务器端保持状态的方案。同时我们也看到， 由于采用服务器端保持状态的方案在客户端也需要保存一个标识， 所以session机制可能需要借助于cookie机制来达到保存标识的目的，但实际上它还有其他选择。 cookie机制。正统的cookie分发是通过扩展HTTP协议来实现的， 服务器通过在HTTP的响应头中加上一行特殊的指示以提示浏览器按照指示生成相应的cookie。 然而纯粹的客户端脚本如JavaScript或者VBScript也可以生成cookie。 而cookie的使用是由浏览器按照一定的原则在后台自动发送给服务器的。 浏览器检查所有存储的cookie，如果某个cookie所声明的作用范围大于等于将要请求的资源所在的位置， 则把该cookie附在请求资源的HTTP请求头上发送给服务器。 cookie的内容主要包括：名字，值，过期时间，路径和域。 路径与域一起构成cookie的作用范围。 若不设置过期时间，则表示这个cookie的生命期为浏览器会话期间， 关闭浏览器窗口，cookie就消失。这种生命期为浏览器会话期的cookie被称为会话cookie。 会话cookie一般不存储在硬盘上而是保存在内存里，当然这种行为并不是规范规定的。 若设置了过期时间，浏览器就会把cookie保存到硬盘上，关闭后再次打开浏览器， 这些cookie仍然有效直到超过设定的过期时间。 存储在硬盘上的cookie可以在不同的浏览器进程间共享，比如两个IE窗口。 而对于保存在内存里的cookie，不同的浏览器有不同的处理方式session机制。 session机制是一种服务器端的机制，服务器使用一种类似于散列表的结构（也可能就是使用散列表）来保存信息。 当程序需要为某个客户端的请求创建一个session时， 服务器首先检查这个客户端的请求里是否已包含了一个session标识（称为session id）， 如果已包含则说明以前已经为此客户端创建过session， 服务器就按照session id把这个session检索出来使用（检索不到，会新建一个）， 如果客户端请求不包含session id，则为此客户端创建一个session并且生成一个与此session相关联的session id， session id的值应该是一个既不会重复，又不容易被找到规律以仿造的字符串，这个session id将被在本次响应中返回给客户端保存。保存这个session id的方式可以采用cookie，这样在交互过程中浏览器可以自动的按照规则把这个标识发送给服务器。一般这个cookie的名字都是类似于SEEESIONID。但cookie可以被人为的禁止，则必须有其他机制以便在cookie被禁止时仍然能够把session id传递回服务器。经常被使用的一种技术叫做URL重写，就是把session id直接附加在URL路径的后面。还有一种技术叫做表单隐藏字段。就是服务器会自动修改表单，添加一个隐藏字段，以便在表单提交时能够把session id传递回服务器。比如： &lt;form name=\"testform\" action=\"/xxx\"&gt; &lt;input type=\"hidden\" name=\"jsessionid\" value=\"ByOK3vjFD75aPnrF7C2HmdnV6QZcEbzWoWiBYEnLerjQ99zWpBng!-145788764\"&gt; &lt;input type=\"text\"&gt; &lt;/form&gt; 实际上这种技术可以简单的用对action应用URL重写来代替。 cookie 和session 的区别： 1、cookie数据存放在客户的浏览器上，session数据放在服务器上。 2、cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗,考虑到安全应当使用session。 3、session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能, 考虑到减轻服务器性能方面，应当使用COOKIE。 4、单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。 5、所以个人建议：将登陆信息等重要信息存放为SESSION,其他信息如果需要保留，可以放在COOKIE中 Jwt和一些权限 JWT 一般和 OAuth2 使用。 对外服务器使用 OAuth2，类似于三方的 API ; 内部使用 JWT 进行服务与服务间的交互，也就是内网间的传输。 OAuth2 进行授权用，JWT 是让系统知道你是谁。 OAuth2 转 JWT 一般在网关层进行转换。","permalink":"https://codermino.github.io/2020/06/25/cookie%E5%92%8Csession%E7%9A%84%E5%8C%BA%E5%88%AB/","photos":[]},{"tags":[{"name":"爬虫下载图片","slug":"爬虫下载图片","permalink":"https://codermino.github.io/tags/%E7%88%AC%E8%99%AB%E4%B8%8B%E8%BD%BD%E5%9B%BE%E7%89%87/"}],"title":"网页图片批量获取（Python教程）","date":"2020/06/25","text":"图片下载（知识点） urllib 库 我们首先了解一下 urllib 库，它是 Python 内置的 HTTP 请求库，也就是说我们不需要额外安装即可使用，它包含四个模块： 第一个模块 request，它是最基本的 HTTP 请求模块，我们可以用它来模拟发送一请求。 就像在浏览器里输入网址，然后敲击回车一样，只需要给库方法传入 URL ， 还有额外的参数，就可以模拟实现这个过程了； 第二个 error 模块即异常处理模块，如果出现请求错误，我们可以捕获这些异常， 然后进行重试或其他操作，保证程序不会意外终止； 第三个 parse 模块是一个工具模块，提供了许多 URL 处理方法，比如拆分、解析、合并等等的方法； 第四个模块是 robotparser，主要是用来识别网站的 robots.txt 文件， 然后判断哪些网站可以爬，哪些网站不可以爬，其实用的比较少。 使用 urlopen() 发送请求 urllib.request 模块提供了最基本的构造 HTTP 请求的方法，利用它可以模拟浏览器的一个请求发起过程，同时它还带有处理 authenticaton（授权验证）、 redirections（重定向)、 cookies（浏览器 Cookies）以及其它内容。 接下来，我们来感受下它的强大之处，以百度为例 ，我们把网页爬取下来。 code: import urllib.request response = urllib.request.urlopen('https://www.baidu.com') print(response.read().decode('utf-8')) urllib.request.urlopen（URL） ：发送 HTTP 请求，返回为 HTTPResponse； response.read() : 获取 HTTP 请求之后响应的内容。 IO open() file object = open(file_name [, access_mode][, buffering]) 打开 file 对象，并返回对应的数据流。如果打开失败，则抛出 IOError异常。 file_name： file_name 变量是一个包含了你要访问的文件名称的字符串值； access_mode ： access_mode 决定了打开文件的模式：只读( r)，写入(w)，追加(a)，创建(x)等。这个参数是非强制的，默认文件访问模式为只读( r)； buffering : 如果 buffering 的值被设为 0，就不会有寄存。如果 buffering 的值取 1，访问文件时会寄存行。如果将 buffering 的值设为大于 1 的整数，表明这就是寄存区的缓冲大小。如果取负值，则寄存区的缓冲大小为系统默认。 上面介绍了这么多知识点，接下来举个“栗子”吧，让我们体验下如何使用 open() 函数。 # 打开一个文件(文件必须已经存在) fo = open(\"example.txt\", \"w\") fo.write( \"\"\"这个博主值得你关注! 这篇博客值得你点赞！ \"\"\") # 关闭打开的文件 fo.close() OS库 os 模块代表了程序所在的操作系统，主要用于获取程序运行所在操作系统的相关信息。 举个“栗子”：创建目录： import os # 创建的目录 path = \"/tmp/home/monthly/daily/hourly\" os.mkdir(path); print(\"目录已创建\") os.mkdir()创建该目录，若目录已存在会报错 再举个“栗子”：判断文件或目录是否已存在： import os exists = os.path.exists(\"foo.txt\") if exists: abspath = os.path.abspath(\"foo.txt\") print(abspath) else: print(\"文件不存在\") os.path.exists()判断目录或文件是否存在 os.path.abspath()返回绝对路径 正则表达式（知识点） 为什么使用正则表达式？ 1、典型的搜索和替换操作，要求您提供与预期的搜索结果匹配的确切文本。虽然这种技术， 对于对静态文本执行简单搜索和替换任务，可能已经足够了，但它缺乏灵活性， 若采用这种方法搜索动态文本，也不是不可能，至少也会变得很困难。 2、比如说，判断邮箱格式是否正确、手机号格式是否正确。 这种需求如果不使用正则匹配的话，那么就需要写很多逻辑进行 equals 操作。 想一想都很麻烦，麻烦的原因是 equals 操作只能确切匹配，缺乏灵活度。 3、而正则就不同了，正则可以使用限定符，匹配字符出现的次数，这样一来灵活度都高了。 4、正则表达式是一个以简单直观的方式通过寻找模式匹配文本的工具 正则表达式的重复限定符 限定符用来指定正则表达式的一个给定组件，必须要出现多少次才能满足匹配。 有 * 或 + 或 ? 或 &#123;n&#125; 或 &#123;n,&#125; 或 &#123;n,m&#125; 共 6种。 如上图 正则表达式的特殊字符类 如上图 正则表达式的分组 要实现分组很简单，使用 ()即可。 从正则表达式的左边开始看，看到的第一个左括号 (表示表示第一个分组，第二个表示第二个分组，依次类推。 a='&lt;div&gt;&lt;a href=\"https://support.google.com/chrome/?p=ui_hotword_search\" target=\"_blank\"&gt;python正则表达式之分组&lt;/a&gt;&lt;p&gt;dfsl&lt;/p&gt;&lt;/div&gt;' print(re.search(r'&lt;a.*&gt;(.*)&lt;/a&gt;',a).group(1)) 输出： python正则表达式之分组 需要注意的是，有一个隐含的全局分组（就是索引号为 0的分组），就是整个正则表达式匹配的结果。 如果正则表达式包含组，则re.findall()返回组的列表 re 库的 findall 函数 在字符串中，找到正则表达式所匹配的所有子串，并返回一个列表。如果没有找到匹配的，则返回空列表。 举个“栗子”：查找字符串中的所有数字。 ort re result1 = re.findall(r'\\d+', 'runoob 123 google 456') result2 = re.findall(r'\\d+', 'run88oob123google456', 0, 10) print(result1) print(result2) ['123', '456'] ['88', '12'] 正则表达式的懒惰匹配算法 针对 正则表达式的重复限定符 默认情况下，Python正则表达式的匹配算法采用贪婪性算法（尽可能多的重复前导字符） 如果正则表达式的重复限定符的后面加后缀?，则正则表达式引擎使用懒惰性匹配算法（尽可能少的重复前导字符） 图片链接提取（例题） 使用 urllib 访问 http://www.tencent.com/ 网页，提取其网页中所有的图片链接。 import urllib.request as req import re \"\"\" 爬取网页内容 \"\"\" def getHTML(url): response = req.urlopen(url) return response.read().decode('utf-8') # 所爬取网站为utf-8编码 \"\"\" 获取网页中全部图片的链接 - 如果网页爬取的超链接为相对路径，需要与网页根路径进行补全 - 网页爬取的超链接如果有重复项，需要去重（不一定有重复，但保险起见） \"\"\" def getImgUrls(html): root = 'http://www.tencent.com/' imgUrls = re.findall(r'img src=\"(.*?)\".*&gt;', html) temp = [] for url in imgUrls: if url not in temp: temp.append(url) for index, url in enumerate(temp): if root not in url: temp[index] = root + url return temp if __name__ == '__main__': url = 'http://www.tencent.com/' html = getHTML(url) imgUrls = getImgUrls(html) for url in imgUrls: print(url) 输出效果（运行时间为2020年5月7日，网站内容可能会变哦）： http://www.tencent.com//data/index/index_detail_1.jpg http://www.tencent.com//data/index/index_detail_2.jpg http://www.tencent.com//data/index/index_detail_3.jpg http://www.tencent.com//img/index/tencent_logo.png 文本内容分析（例题） 通过路径 /root/score.txt，以只读的方式读取 score.txt 文件； 获取 2016年一本线最高的的三个省份，并将其打印到控制台（格式为： 省份**********分数） score.txt 文件数据类似如下： 甘肃 490 632 621 625 630 597 608 吉林 530 658 639 649 634 599 615 新疆 464 673 617 630 612 534 578 广西 502 642 601 620 603 584 592 上海 360 489 475 480 / / / 广东 508 641 600 613 619 585 597 内蒙古 484 641 615 627 623 558 597 陕西 470 665 628 638 639 596 615 四川 532 665 626 643 651 612 623 黑龙江 486 667 623 641 628 580 600 安徽 518 655 620 631 647 608 621 河北 525 682 654 667 669 640 649 江西 529 645 614 629 613 589 599 浙江 600 692 670 679 676 652 661 湖南 517 662 635 644 646 593 609 宁夏 465 637 565 597 590 481 526 山东 537 679 655 665 660 597 637 河南 523 665 644 652 659 629 638 山西 519 639 617 625 638 579 599 天津 512 659 634 649 600 537 567 北京 548 662 607 629 613 570 592 重庆 525 671 644 655 654 634 642 云南 525 680 653 663 663 627 639 青海 416 596 562 580 571 502 533 江苏 353 404 376 386 384 355 366 福建 465 632 614 623 606 485 576 海南 602 829 710 750 737 672 700 贵州 473 671 627 643 658 600 616 辽宁 498 660 624 637 641 607 621 湖北 512 665 622 640 637 604 614 以第一行数据为例，对数据结构进行说明： 甘肃 490 632 621 625 630 597 608 ， 第一列为省份， 第二列为 2016年的一本线分数 490， 第三列为 2015年的一本线分数 632， 其次类推，分别是 2014、 2013、 2012、 2011、 2010 年的分数线。 代码： # 先读取所有省份和对应的2016年一本线分数，分别存入列表prov和score prov, score = [], [] with open(r'/root/score.txt', 'r') as f: for line in f.readlines(): t = line.split() prov.append(t[0]) score.append(int(t[1])) # 对prov和score中的数据进行排序 temp = list(zip(prov, score)) # 把prov和score压缩为一个列表tmp ''' 对temp排序，当列表元素是元组时， 需要以元组的第二个元素进行排序，即根据一本线分数排序， 所以写了takeSecond()函数 ''' def takeSecond(elem): return elem[1] temp.sort(reverse=True, key=takeSecond) # 降序排序 # 获取 2016年一本线最高的的三个省份，并将其打印到控制台 for i in range(3): p = str(temp[i][0]) s = str(temp[i][1]) print(p + '**********' + s) 效果： 海南**********602 浙江**********600 北京**********548 图片批量下载（例题） 以http://www.tencent.com/该网址为例，将网页上的所有图片批量下载到一个文件夹中。 三个步骤就可以完成了 如何获取 HTML 源码， 如何获取 HTML 源码上的指定标签， 如何使用 OS 模块完成目录的创建。 import urllib.request as req import re import os # 获取网页的HTML源码,返回HTML源码 def getHTML(url): response = req.urlopen(url) return response.read().decode('utf-8') # 从HTML代码中提取图片的网址,返回图片链接列表 def getImgUrls(html): root = 'http://www.tencent.com/' imgUrls = re.findall(r'img src=\"(.*?)\".*&gt;', html) temp = [] for url in imgUrls: if url not in temp: temp.append(url) for index, url in enumerate(temp): if root not in url: temp[index] = root + url return temp # 下载一幅图片，图片的链接为url，下载后的图片名字为name def downloadImg(url, name): response = req.urlopen(url) img = open(name, 'wb') # 以二进制形式写入 img.write(response.read()) img.close() # 将url对应网页上所有图片下载到dirPath文件夹 def downloadAllImg(url, dirPath): # 若文件夹不存在，则创建 exists = os.path.exists(dirPath) if not exists: os.mkdir(dirPath) # 获取网页上所有图片的网址 html = getHTML(url) imgUrls = getImgUrls(html) print(os.path) # 下载图片，注意异常处理 for url in imgUrls: imgName = os.path.split(url)[1] # 获取文件名 filePath = os.path.join(dirPath, imgName) # 存放入文件夹内的完整路径名 try: downloadImg(url, filePath) except: continue if __name__ == '__main__': url = 'http://www.tencent.com/' dirPath = 'D:\\imgs' downloadAllImg(url, dirPath) os.path.split(path) 以 path 中最后一个 / 作为分隔符，分隔后，将索引为0的视为目录（路径），将索引为1的视为文件名 os.path.join(path1, path2, ...) 以/拼接参数","permalink":"https://codermino.github.io/2020/06/25/%E7%BD%91%E9%A1%B5%E5%9B%BE%E7%89%87%E6%89%B9%E9%87%8F%E8%8E%B7%E5%8F%96%EF%BC%88Python%E6%95%99%E7%A8%8B%EF%BC%89/","photos":[]},{"tags":[{"name":"火柴","slug":"火柴","permalink":"https://codermino.github.io/tags/%E7%81%AB%E6%9F%B4/"}],"title":"火柴软件使用说明","date":"2020/06/24","text":"呼叫火柴 火柴是一款PC端的 快速启动+文件搜索+局域网传文件 软件。使用方法十分简单，双击 Ctrl 键 呼出搜索框，输入内 容即可搜索，再次双击 Ctrl 键 则可以关闭桌面搜索框。 快速启动 火柴增加了“快速启动”面板。可以将常用的软件、文件、网址固定在面板中（每排8个，共4排，最多放31个。）可 根据自己的习惯增加，例如像我这个样子。 快速启动拓展 如果面板放满了，还可以搜索软件名进行软件启动。火柴支持 程序名/文件名（如输入“QQ”，打开”QQ”），名称 缩写（如“PS”，打开“photoshop”）,乃至软件俗称（如“吃鸡”）。 文件搜索 使用Windows搜索的都知道，由于索引服务的原因，导致Windows自带搜索出奇的缓慢，经常要等数分钟，才会搜出 结果。众所周知，everything是一款强大的本地搜索软件，基于everything内核的火柴也是如此。而且，火柴搜索显示 上做出优化，不用用户编写复杂的正则表达式(因为不是每个人都是大牛)。 网络搜索 此外，火柴还支持“网络搜索”。集成了若干搜索引擎，默认可以进行百度搜索、淘宝搜索、微信搜索等。如果想要 搜索的内容，在浏览器内有收藏书签，火柴会在搜索结果中提示，并且使用收藏书签所在的浏览器打开，充分照顾用 户使用习惯。此外，网络搜索还支持高级搜索。（玩法太多，此处省略10万字） 局域网传文件 火柴另一个功能就是局域网传文件。局域网文件中，如果是网线连接，速度最高可达110MB/s，wifi连接最高速度也能达 到70MB/s。 小程序 火柴内集成了24个实用得小工具——“火柴小程序”。小程序涵盖了工作、学习、娱乐、生活等诸多方面，可满足大部 分人的需求。调用小程序也很方便，输入“xcx”,就可以查看小程序列表，并启动需要的小程序。 小程序列表 也可以直接输入小程序对应得命令，启动对应得小程序。如输入“fy”，启动“翻译小程序”；输入“time”，启动 “时间戳小程序” 部分小程序，还支持快捷键。例如【alt】+【Q】，启动“火柴截图”；【alt】+【1】启动“综合导航”（全屏面板） 皮肤 此外，火柴还支持支换肤。如果不喜欢素颜的默认皮肤，可以到皮肤中心选择下载自己喜欢的皮肤，或者 干脆自己动手制作。（ps: 我更喜欢自己动手制作）","permalink":"https://codermino.github.io/2020/06/24/%E7%81%AB%E6%9F%B4%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/","photos":[]},{"tags":[{"name":"this.$nextTick","slug":"this-nextTick","permalink":"https://codermino.github.io/tags/this-nextTick/"}],"title":"this.$nextTick","date":"2020/03/31","text":"原理 1.vue依靠数据驱动来完成视图和dom的渲染 2.vue的响应式不是数据发生变化之后立即变化，更新的过程是异步的 3.如果想要在created钩子函数中进行dom操作，created钩子函数中是在页面创建的时候进行调用， 可能还未对页面中的dom元素进行渲染完成。所以无法直接进行操作，需要通过this.$nextTick()来完成。 验证 创建对应的html页面 span标签中显示的内容是data中的value的值 点击button按钮之后会触发changeValue事件，修改data中的value的值 主要是验证span标签中value的值的变化过程 &lt;button @click=\"changeValue\"&gt;点击改变value&lt;/button&gt; &lt;span ref=\"container\"&gt;&#123;&#123;this.value&#125;&#125;&lt;/span&gt; 创建对应的数据和钩子函数 created()&#123; console.log('开始执行created函数'); console.log(this.value); console.log(this.$refs.container); this.$nextTick(()=&gt;&#123; console.log('created中的$nextTick函数'); &#125;) &#125;, mounted() &#123; console.log('开始执行mounted函数'); console.log(this.$refs.container.innerHTML); this.$nextTick(()=&gt;&#123; console.log('mounted中的$nextTick函数'); &#125;) &#125;, data()&#123; return&#123; value:'改变之前的内容(old)' &#125; &#125;, methods:&#123; changeValue()&#123; this.value = '改变之后的内容(new)'; console.log(this.$refs.container.innerText); this.$nextTick(()=&gt;&#123; console.log(this.$refs.container.innerText); &#125;) &#125; &#125; 输出 页面中的输出结果 test.vue?b018:13 开始执行created函数 test.vue?b018:14 改变之前的内容(old) test.vue?b018:15 undefined test.vue?b018:21 开始执行mounted函数 test.vue?b018:22 改变之前的内容(old) test.vue?b018:17 created中的$nextTick函数 test.vue?b018:24 mounted中的$nextTick函数 test.vue?b018:35 改变之前的内容(old) test.vue?b018:37 改变之后的内容(new) 输出结果分析 结果分析 页面打开后调用created钩子函数 输出相应的打印结果，可以看到在第15行结果为undefined(输出的是span标签) 可以看出在created钩子函数调用的时候，页面的dom元素还没有渲染完成 在第17行可以看到，在页面的dom元素渲染完成之后，会按照生命周期顺序执行created和mouted钩子函数中的this.$nextTick()函数 并且输出对应的内容 在点击了按钮之后，改变了data中的value的值，页面中也进行了dom的刷新，但是... 通过35行的打印可以知道，此时span标签中的内容还是修改之前的内容 通过37行的打印可以知道，在dom元素彻底渲染完成之后，span标签中的内容也完成了更新。(此时打印的内容是更新完的value的内容) 总结 this.$nextTick() veu的响应式的更新的过程是异步的。 是保证在dom元素渲染完成之后再进行某个操作。 所以如果希望某个函数或者数据的赋值等操作是在dom元素渲染完成之后再进行，那么可以用this.$nextTick()","permalink":"https://codermino.github.io/2020/03/31/this-nextTick/","photos":[]},{"tags":[{"name":"stream处理大文件","slug":"stream处理大文件","permalink":"https://codermino.github.io/tags/stream%E5%A4%84%E7%90%86%E5%A4%A7%E6%96%87%E4%BB%B6/"}],"title":"nodejs的stream","date":"2020/02/25","text":"读取 const fs = require('fs'); const fileReadStream = fs.createReadStream(\"input.json\"); fileReadStream.once('data',(chunk)=&gt;&#123; console.log(chunk.toString()); &#125;); fileReadStream.on(\"end\",()=&gt;&#123; console.log('end'); &#125;); fileReadStream.on('error',(err)=&gt;&#123; console.log(err); &#125;); 读取并写入 const fs = require('fs'); const fileReadStream = fs.createReadStream(\"input.json\"); const fileWriteStream = fs.createWriteStream('output.json'); let count = 0; fileReadStream.on('data',(chunk)=&gt;&#123; console.log(`$&#123;++count&#125; 接收到: $&#123;chunk.length&#125;`); fileWriteStream.write(chunk); &#125;); fileReadStream.on(\"end\",()=&gt;&#123; console.log('end'); &#125;); fileReadStream.on('error',(err)=&gt;&#123; console.log(err); &#125;); 管道流写入 const fs = require('fs'); const fileReadStream = fs.createReadStream(\"input.json\"); const fileWriteStream = fs.createWriteStream('output.json'); //通过管道流的方式进行写入 fileReadStream.pipe(fileWriteStream); 管道流产生一个gz压缩文件 const fs = require('fs'); const zlib = require('zlib'); const fileReadStream = fs.createReadStream(\"input.json\"); const fileWriteStream = fs.createWriteStream('output.gz'); fileWriteStream.on('pipe',(source)=&gt;&#123; console.log(source); &#125;); fileReadStream .pipe(zlib.createGzip()) .pipe(fileWriteStream);","permalink":"https://codermino.github.io/2020/02/25/nodejs%E7%9A%84stream/","photos":[]},{"tags":[{"name":"gm","slug":"gm","permalink":"https://codermino.github.io/tags/gm/"}],"title":"通过控制台使用gm裁剪图片","date":"2020/02/15","text":"转换图片格式 gm convert input output 改变图片大小 gm convert -quality 80 -resize 100×100 input.jpg output.jpg 添加水印文字 -font 字体 -fill 填充颜色 -pointsize 字体大小 -draw 内容 gm convert -font Arial -fill blue -pointsize 18 -draw \"text 100,100 'www.abc.com'\" input output","permalink":"https://codermino.github.io/2020/02/15/%E9%80%9A%E8%BF%87%E6%8E%A7%E5%88%B6%E5%8F%B0%E4%BD%BF%E7%94%A8gm%E8%A3%81%E5%89%AA%E5%9B%BE%E7%89%87/","photos":[]},{"tags":[{"name":"gm裁切图片(1)","slug":"gm裁切图片-1","permalink":"https://codermino.github.io/tags/gm%E8%A3%81%E5%88%87%E5%9B%BE%E7%89%87-1/"}],"title":"gm裁切图片(1)","date":"2020/02/05","text":"引入相关包 const fs = require('fs'),gm = require('gm'); 缩放 gm('input.jpg') .resize(50, 50,\"!\") .write('output.jpg', function (err) &#123; if (err) &#123; console.log(err); &#125; &#125;); 裁剪指定位置 gm('./demo.jpg') .crop(364, 480, 82, 3) .write('./cut.jpg', function (err) &#123; if (!err) console.log('crazytown has arrived'); &#125;);","permalink":"https://codermino.github.io/2020/02/05/gm%E8%A3%81%E5%88%87%E5%9B%BE%E7%89%87-1/","photos":[]},{"tags":[{"name":"md5加密注册表单","slug":"md5加密注册表单","permalink":"https://codermino.github.io/tags/md5%E5%8A%A0%E5%AF%86%E6%B3%A8%E5%86%8C%E8%A1%A8%E5%8D%95/"}],"title":"md5加密注册表单","date":"2020/02/05","text":"文件夹的创建 创建public文件夹用来存放jquery文件 创建views文件夹用来存放前端页面 创建models文件夹用来存放md5.js文件 register前端页面 &lt;!DOCTYPE html&gt; &lt;html lang=\"en\"&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;注册&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;div&gt; &lt;form action=\"\" method=\"post\"&gt; &lt;label for=\"username\"&gt;&lt;/label&gt; &lt;p&gt;用户名：&lt;input name=\"userName\" type=\"text\" id=\"username\"/&gt;&lt;/p&gt; &lt;label for=\"password\"&gt;&lt;/label&gt; &lt;p&gt;密 码：&lt;input name=\"password\" type=\"password\" id=\"password\"/&gt;&lt;/p&gt; &lt;p&gt;&lt;input type=\"button\" value=\"注册\" id=\"zhuce\"&gt;&lt;/p&gt; &lt;/form&gt; &lt;/div&gt; &lt;script type=\"text/javascript\" src=\"/jquery-1.11.3.min.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\"&gt; //用ajax提交表单 $(\"#zhuce\").click(function()&#123; $.post(\"/doregist\",&#123; \"username\" : $(\"#username\").val(), \"password\" : $(\"#password\").val() &#125;,function(result)&#123; if(result === \"1\")&#123; alert(\"注册成功\"); window.location.href=\"/login\"; &#125;else&#123; alert(\"注册失败\"); &#125; &#125;) &#125;); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; login前端页面 &lt;!doctype html&gt; &lt;html lang=\"en\"&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;登录&lt;/h1&gt; &lt;div&gt; &lt;form action=\"\" method=\"post\"&gt; &lt;label for=\"dengluming\"&gt;&lt;/label&gt; &lt;p&gt; 登录名： &lt;input type=\"text\" id=\"dengluming\"/&gt; &lt;/p&gt; &lt;label for=\"mima\"&gt;&lt;/label&gt; &lt;p&gt; 密码： &lt;input type=\"password\" id=\"mima\"/&gt; &lt;/p&gt; &lt;p&gt; &lt;input id=\"denglu\" type=\"button\" value=\"登陆\"/&gt; &lt;/p&gt; &lt;/form&gt; &lt;/div&gt; &lt;script type=\"text/javascript\" src=\"/jquery-1.11.3.min.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\"&gt; //用ajax提交表单 $(\"#denglu\").click(function()&#123; $.post(\"/dologin\",&#123; \"dengluming\" : $(\"#dengluming\").val(), \"mima\" : $(\"#mima\").val() &#125;,function(result)&#123; if(result === \"1\")&#123; alert(\"登陆成功\"); window.location.href=\"/index\"; &#125;else if(result === \"-2\")&#123; alert(\"没有这个注册用户\"); &#125;else if(result === \"-1\")&#123; alert(\"密码不正确\"); &#125; &#125;) &#125;); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; md5.js const crypto = require(\"crypto\"); module.exports = function(password)&#123; let md5 = crypto.createHash('md5'); return md5.update(password).digest('base64'); &#125;; 引入相关的包 const express = require('express'); const path = require('path'); const ejs = require('ejs'); const MongoClient = require('mongodb').MongoClient; const md5 = require(\"./model/md5.js\"); const formidable = require('formidable'); const session = require('express-session'); express中间件 使用express中间件,并且在3000端口监听 const app = express(); app.listen(3000,function () &#123; console.log('server is running...'); &#125;); 使用html模板引擎 将ejs模板引擎转为html模板引擎 app.set('views', path.join(__dirname, 'views')); app.engine('html', ejs.__express); app.set('view engine', 'html'); 使用express-session中间件 使用express-session中间件,并且如果用户主动刷新页面那么session自动重新计时，并且session的有效时间为60s app.use(session(&#123; secret: 'keyboard cat', name : 'login', resave: true,//是否允许session重新设置 saveUninitialized: false, cookie: &#123;maxAge: 60 * 1000&#125;, rolling: true //add 刷新页面 session 过期时间重置 &#125;)); 开放静态资源服务 将Public文件夹开放出来 app.use(express.static('./public')); 渲染前端页面 设置重定向,一开始的时候自动重定向到register路由,并且渲染register.html文件 app.get('/',function (req,res) &#123; res.redirect('/register'); &#125;); app.get('/register',function (req,res) &#123; res.render('register'); &#125;); app.get('/login',function (req,res) &#123; res.render('login'); &#125;); 注册接口 app.post('/dologin',function (req,res) &#123; let form = new formidable.IncomingForm(); form.parse(req, function(err, fields, files)&#123; const array = []; const username = fields.dengluming; let password = fields.mima; password = (你的md5加密方式) 例如:md5(password); const url = \"mongodb://localhost:27017/\"; //连接数据库 MongoClient.connect(url, &#123;useUnifiedTopology:true&#125;, (err, client)=&gt; &#123; //回调函数表示链接成功做的事情，db参数就是连接上的数据库实体 if(err) &#123; console.log(\"数据库连接失败\"); return ; &#125; //插入数据，集合如果不存在，也没有关系，程序会帮你创建 const db = client.db('learnnode'); const result = db.collection('Student').find(&#123;username:username&#125;); result.each(function (err, doc) &#123; if(err) &#123; return; &#125; if(doc != null) &#123; array.push(doc); //放入结果数组 &#125;else &#123; let checkNum = 0; const resultNum = array.length; if(resultNum === 0)&#123; res.send('-2'); &#125;else &#123; //遍历结束，没有更多的文档 array.forEach(function (data) &#123; if(data.password === password)&#123; req.session.login = true; req.session.username = username; req.session.password = password; res.send('1'); &#125;else &#123; checkNum++; &#125; &#125;); if(checkNum === resultNum)&#123; res.send('-1'); &#125; &#125; &#125; &#125;); &#125;); &#125;); &#125;); 注册接口 app.post('/doregist',function (req,res) &#123; let form = new formidable.IncomingForm(); form.parse(req, function(err, fields, files)&#123; const username = fields.username; let password = fields.password; const url = \"mongodb://localhost:27017/\"; MongoClient.connect(url, &#123;useUnifiedTopology:true&#125;, (err, client)=&gt; &#123; //回调函数表示链接成功做的事情，db参数就是连接上的数据库实体 if(err) &#123; console.log(\"数据库连接失败\"); return ; &#125; //插入数据，集合如果不存在，也没有关系，程序会帮你创建 const db = client.db('learnnode'); password = md5(md5(password).substr(4,7) + md5(password)); const myObj = &#123;username: username, password: password&#125;; db.collection('Student').insertOne(myObj,function (err,result) &#123; if(err)&#123; console.log(err); res.send('-1'); &#125;else &#123; console.log('插入数据成功'); res.send('1'); &#125; client.close(); &#125;); &#125;); &#125;); &#125;);","permalink":"https://codermino.github.io/2020/02/05/md5%E5%8A%A0%E5%AF%86%E6%B3%A8%E5%86%8C%E8%A1%A8%E5%8D%95/","photos":[]},{"tags":[{"name":"session的使用","slug":"session的使用","permalink":"https://codermino.github.io/tags/session%E7%9A%84%E4%BD%BF%E7%94%A8/"}],"title":"session的使用","date":"2020/02/01","text":"基本使用 const express = require('express'); //引入express-session中间件 const session = require('express-session'); const app = express(); app.set('trust proxy', 1) ;// trust first proxy //使用session并且配置相关参数 app.use(session(&#123; secret: 'keyboard cat', resave: false, saveUninitialized: true // cookie: &#123; secure: true &#125; &#125;)); app.get('/',function (req,res) &#123; if(req.session.login)&#123; res.send('欢迎您：'+req.session.username); &#125;else &#123; res.send('没有登录'); &#125; &#125;); app.get('/login',function (req,res) &#123; req.session.login = true; req.session.username = '张三'; res.send('登录成功'); &#125;); app.listen(3000,function () &#123; console.log('server is running...'); &#125;);","permalink":"https://codermino.github.io/2020/02/01/session%E7%9A%84%E4%BD%BF%E7%94%A8/","photos":[]},{"tags":[{"name":"cookie的使用","slug":"cookie的使用","permalink":"https://codermino.github.io/tags/cookie%E7%9A%84%E4%BD%BF%E7%94%A8/"}],"title":"cookie的使用","date":"2020/02/01","text":"基本使用 const express = require('express'); //使用cookie-parser中间件 const cookieParser = require('cookie-parser'); const app = express(); app.use(cookieParser()); app.get('/',function (req,res) &#123; res.send(req.cookies.xihao); &#125;); // http://localhost:3000/gonglue?dest=北京 app.get('/gonglue',function (req,res) &#123; const destination = req.query.dest; //先取出cookie,然后再设置cookie const likes = req.cookies.xihao || []; likes.push(destination); //maxAge设置最大存活时间，在nodejs中是以毫秒为单位(900000ms),但是在浏览器的cookie中会是以秒为单位(900s) res.cookie('xihao',likes,&#123; maxAge: 900000, httpOnly: true &#125;); res.send(destination+'旅游攻略'); &#125;); app.listen(3000,function () &#123; console.log('server is running...'); &#125;);","permalink":"https://codermino.github.io/2020/02/01/cookie%E7%9A%84%E4%BD%BF%E7%94%A8/","photos":[]},{"tags":[{"name":"app.use中间件","slug":"app-use中间件","permalink":"https://codermino.github.io/tags/app-use%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"title":"app.use中间件","date":"2020/01/30","text":"使用 const express = require('express'); const app = express(); //在使用app.use中间件的时候如果不指定路由，那么默认是/ //会匹配到/、/abc、/abc/123等路由 如果在浏览器中输入的路由是http://localhost:3000/user/456/abc app.use(function(req, res, next)&#123; //GET /user/456/abc console.log('%s %s', req.method, req.url); next(); &#125;); 那么和get、post不同的是use会向下接着匹配 app.use('/user',function(req, res, next)&#123; const basePath = req.baseUrl; const path = req.path; /user console.log(basePath); /456/abc console.log(path); res.send('Hello World'); &#125;); app.listen(3000); 开放静态资源文件夹 //开放同级目录下的public文件夹，并且在路由的时候使用/static代替 app.use('/static',express.static(__dirname + '/public')); 原生开放静态资源原理 const express = require('express'); const fs = require('fs'); const app = express(); app.use(openStatic); app.listen(3000,function () &#123; console.log('server is running...'); &#125;); function openStatic(req,res,next) &#123; const filePath = req.path; fs.readFile(__dirname+filePath,function (err,data) &#123; if(err)&#123; next() &#125;else &#123; res.send(data.toString()); &#125; &#125;) &#125; 优先级 会按照从上到下的优先级顺序执行 app.use(express.static(__dirname + '/public')); app.use(express.static(__dirname + '/files')); app.use(express.static(__dirname + '/uploads'));","permalink":"https://codermino.github.io/2020/01/30/app-use%E4%B8%AD%E9%97%B4%E4%BB%B6/","photos":[]},{"tags":[{"name":"将ejs模板引擎修改为html模板引擎","slug":"将ejs模板引擎修改为html模板引擎","permalink":"https://codermino.github.io/tags/%E5%B0%86ejs%E6%A8%A1%E6%9D%BF%E5%BC%95%E6%93%8E%E4%BF%AE%E6%94%B9%E4%B8%BAhtml%E6%A8%A1%E6%9D%BF%E5%BC%95%E6%93%8E/"}],"title":"将ejs模板引擎修改为html模板引擎","date":"2020/01/29","text":"引入 const ejs = require('ejs'); const path = require('path'); 使用html模板引擎 app.set('views', path.join(__dirname, 'views')); app.engine('html', ejs.__express); app.set('view engine', 'html'); 渲染html页面 app.get('/',function (req,res) &#123; res.redirect('/user'); &#125;); app.get('/user',function (req,res) &#123; res.render('form'); &#125;); 渲染原理 在渲染的时候app.set('views', path.join(__dirname, 'views')); 渲染的页面会在views文件夹下寻找指定名的文件(上述例子寻找views/form.html) 将渲染ejs文件修改为渲染html文件 app.engine('html', ejs.__express); //如果不想使用views这个文件夹，可以使用下面的语句进行修改 app.set('views','文件夹的名字'); app.set('view engine', 'html');","permalink":"https://codermino.github.io/2020/01/29/%E4%BD%BF%E7%94%A8html%E6%A8%A1%E6%9D%BF%E5%BC%95%E6%93%8E/","photos":[]},{"tags":[{"name":"body-parser","slug":"body-parser","permalink":"https://codermino.github.io/tags/body-parser/"}],"title":"body-parser的使用","date":"2020/01/29","text":"安装 npm install body-parser 使用 var bodyParser = require('body-parser'); app.use(bodyParser.urlencoded(&#123; extended: false &#125;)); // parse application/json app.use(bodyParser.json()); 表单 &lt;!DOCTYPE html&gt; &lt;html lang=\"en\"&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Demo&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;form method=\"post\" action=\"#\"&gt; &lt;label for=\"username\"&gt;&lt;/label&gt; &lt;input id=\"username\" type=\"text\" placeholder=\"请输入姓名\" name=\"username\"/&gt; &lt;input type=\"submit\" value=\"提交\"/&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt; 获取表单数据 app.post('/user',function (req,res) &#123; res.setHeader('Content-Type', 'text/plain'); res.write('you posted:\\n'); res.end(JSON.stringify(req.body, null, 2)); &#125;);","permalink":"https://codermino.github.io/2020/01/29/body-parser%E7%9A%84%E4%BD%BF%E7%94%A8/","photos":[]},{"tags":[{"name":"express","slug":"express","permalink":"https://codermino.github.io/tags/express/"}],"title":"express模板的使用","date":"2020/01/28","text":"安装 npm install express --save Demo const express = require('express') const app = express() app.get('/', function (req, res) &#123; res.send('Hello World') &#125;) app.listen(3000,function()&#123; console,log('正在运行......'); &#125; ) 其他参数 app.get('/abc',function()&#123; res.send('这是二级路由') &#125;) 正则 //匹配路由为/student/后面加上10位数字的路由 app.get(/^\\/student\\/([\\d]&#123;10&#125;)$/,function (req,res) &#123; res.send('学号'+req.params[0]); &#125;); //也可以获取到参数之后，然后再用正则进行验证 app.get('/book/:id',function (req,res) &#123; let id = req.params['id']; let reg = /^[\\d]&#123;6&#125;$/; if (reg.test(id))&#123; res.send(id) &#125;else &#123; res.send('error'); &#125; &#125;); express的参数显示 app.get('/teacher/:id',function (req,res) &#123; res.send('工号'+req.params.id); &#125;); express的参数显示的格式限制 //限制编号后面是3-8为数字的路由 app.get('/master/:iid([\\\\d]&#123;3,8&#125;)',function (req,res) &#123; res.send('编号'+req.params.iid); &#125;); tips res.send()还可以send一个json对象 res.send(&#123; 'data':'这是二级路由' &#125;)","permalink":"https://codermino.github.io/2020/01/28/express%E6%A8%A1%E6%9D%BF%E7%9A%84%E4%BD%BF%E7%94%A8/","photos":[]},{"tags":[{"name":"ejs模板的基本使用","slug":"ejs模板的基本使用","permalink":"https://codermino.github.io/tags/ejs%E6%A8%A1%E6%9D%BF%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"}],"title":"ejs模板的使用","date":"2020/01/28","text":"安装 npm install ejs 基本使用1 //引入ejs const ejs = require('ejs'); //定义字符串 let str = '今天是星期&lt;%= a%&gt;'; //定义data data = &#123; a:'天' &#125;; //ejs渲染str和data let html = ejs.render(str, data); //控制台输出 console.log(html); 基本使用2 1.首先创建一个ejs文件:index.ejs &lt;!doctype html&gt; &lt;html lang=\"en\"&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\"&gt; &lt;title&gt;Document&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;今天是星期&lt;%=a%&gt;&lt;/h1&gt; &lt;/body&gt; &lt;/html&gt; 2.使用ejs模板传数据和进行渲染 //引入fs和ejs const fs = require('fs'); const ejs = require('ejs'); //读取文件(读取当前路径下的index.ejs文件) fs.readFile('./index.ejs',function (err, data) &#123; if(err)&#123; console.log(err); &#125;else&#123; //需要将模板转为字符串,因为在传输过程中是byte流 const template = data.toString(); const dictionary = &#123; a:'天' &#125;; //使用ejs进行渲染，传入的数据有data,和ejs界面需要使用的数据 const html = ejs.render(template, dictionary); //控制台输出渲染之后的结果 console.log(html); &#125; &#125;); 基本使用3 //引入fs、ejs和http const fs = require('fs'); const ejs = require('ejs'); const http = require('http'); //使用http开启一个服务器 let server = http.createServer(function (req, res) &#123; fs.readFile('./index.ejs',function (err, data) &#123; if(err)&#123; console.log(err); &#125;else&#123; const template = data.toString(); const dictionary = &#123; a:'天' &#125;; const html = ejs.render(template, dictionary); //显示 res.writeHead(200,&#123;\"Content-Type\":\"text/html;charset=UTF8\"&#125;); res.end(html) &#125; &#125;); &#125;); //在3000端口监听 server.listen(3000, function () &#123; console.log('服务器启动成功'); &#125;); 基本使用4 //也可以在传递数据的时候传入一个数组 const dictionary = &#123; a:'天', news:['星期一','星期二','星期三'] &#125;; //在前端页面中可以使用for循环遍历 &lt;ul&gt; &lt;% for(let i=0; i&lt;news.length; i++)&#123; %&gt; &lt;li&gt;&lt;%=news[i]%&gt;&lt;/li&gt; &lt;%&#125;%&gt; &lt;/ul&gt; 基本使用5 //也可以传入一个数组对象 people:[ &#123;name:'张三',age:29&#125;, &#123;name:'李四',age:31&#125;, &#123;name:'王五',age:38&#125;, &#123;name:'孙六',age:30&#125; ] &lt;ul&gt; &lt;% for(let i = 0;i&lt;people.length;i++)&#123; if(people[i].age&gt;30)&#123; %&gt; &lt;li&gt;&lt;%= people[i].name%&gt;&lt;/li&gt; &lt;%&#125;%&gt; &lt;%&#125;%&gt; &lt;/ul&gt;","permalink":"https://codermino.github.io/2020/01/28/ejs%E6%A8%A1%E6%9D%BF%E7%9A%84%E4%BD%BF%E7%94%A8/","photos":[]},{"tags":[{"name":"formidable文件改名","slug":"formidable文件改名","permalink":"https://codermino.github.io/tags/formidable%E6%96%87%E4%BB%B6%E6%94%B9%E5%90%8D/"}],"title":"formidable上传文件改名","date":"2020/01/25","text":"引用模块 主要使用的是nodejs的fs模块和path模块 var fs = require('fs'); var sd = require('silly-datetime'); var path = require('path') 具体使用 time = sd.format(new Date(),'YYYYMMDDHHMMSS'); 产生一个过位数的随机数 random = parseInt(Math.random()* 89999 + 10000); extname = path.extname(files.前端表单上传的图片的file的名字).name; oldpath = __dirname + '/' + files.名字.path; 这里使用的新的名字由三部分组成：时间戳、随机数、拓展名 newpath = __dirname + '/uploads/' + time + random + extname; 执行 fs.rename(oldpath, newpath, function(err)&#123; if(err)&#123; throw Error('改名失败'); &#125; res.writeHead(200, &#123;'content-type' : 'text/plain'&#125;); res.end('成功'); &#125;);","permalink":"https://codermino.github.io/2020/01/25/formidable%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E6%94%B9%E5%90%8D/","photos":[]},{"tags":[{"name":"formidable文件上传","slug":"formidable文件上传","permalink":"https://codermino.github.io/tags/formidable%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/"}],"title":"nodejs的formidable","date":"2020/01/25","text":"安装 npm i -S formidable 引用 var formidable = require('formidable'), http = require('http'), util = require('util'); 创建相关路由 http.createServer(function(req, res) &#123; if (req.url == '/upload' &amp;&amp; req.method.toLowerCase() == 'post') &#123; // parse a file upload var form = new formidable.IncomingForm(); form.parse(req, function(err, fields, files) &#123; //在fields中存储的是上传的输入框或者单选框等信息 //在files中存储的是上传的图片或者视频等信息 res.writeHead(200, &#123;'content-type': 'text/plain'&#125;); res.write('received upload:\\n\\n'); res.end(util.inspect(&#123;fields: fields, files: files&#125;)); &#125;); return; &#125; tip: 在前端中的上传的表单中一定要加上:enctype=\"multipart/form-data\" eq: &lt;form action=\"/upload\" enctype=\"multipart/form-data\" method=\"post\"&gt; 相关API参数 -Creates a new incoming form. var form = new formidable.IncomingForm() -Sets encoding for incoming form fields. form.encoding = 'utf-8'; -Sets the directory for placing file uploads in. You can move them later on using fs.rename(). The default is os.tmpdir(). form.uploadDir = \"/my/dir\"; -If you want the files written to form.uploadDir to include the extensions of the original files, set this property to true. form.keepExtensions = false; -Either 'multipart' or 'urlencoded' depending on the incoming request. form.type -Limits the amount of memory all fields together (except files) can allocate in bytes. If this value is exceeded, an 'error' event is emitted. The default size is 20MB. form.maxFieldsSize = 20 * 1024 * 1024; -Limits the size of uploaded file. If this value is exceeded, an 'error' event is emitted. The default size is 200MB. form.maxFileSize = 200 * 1024 * 1024; -Limits the number of fields that the querystring parser will decode. Defaults to 1000 (0 for unlimited). form.maxFields = 1000; -If you want checksums calculated for incoming files, set this to either 'sha1' or 'md5'. form.hash = false; -If this option is enabled, when you call form.parse, the files argument will contain arrays of files for inputs which submit multiple files using the HTML5 multiple attribute. form.multiples = false; Event 'progress' Emitted after each incoming chunk of data that has been parsed. Can be used to roll your own progress bar. form.on('progress', function(bytesReceived, bytesExpected) &#123; &#125;); 'field' Emitted whenever a field / value pair has been received. form.on('field', function(name, value) &#123; &#125;); 'fileBegin' Emitted whenever a new file is detected in the upload stream. Use this event if you want to stream the file to somewhere else while buffering the upload on the file system. form.on('fileBegin', function(name, file) &#123; &#125;); 'file' Emitted whenever a field / file pair has been received. file is an instance of File. form.on('file', function(name, file) &#123; &#125;); 'error' Emitted when there is an error processing the incoming form. A request that experiences an error is automatically paused, you will have to manually call request.resume() if you want the request to continue firing 'data' events. form.on('error', function(err) &#123; &#125;); 'aborted' Emitted when the request was aborted by the user. Right now this can be due to a 'timeout' or 'close' event on the socket. After this event is emitted, an error event will follow. In the future there will be a separate 'timeout' event (needs a change in the node core). form.on('aborted', function() &#123; &#125;); 'end' form.on('end', function() &#123; &#125;); Emitted when the entire request has been received, and all contained files have finished flushing to disk. This is a great place for you to send your response.","permalink":"https://codermino.github.io/2020/01/25/nodejs%E7%9A%84formidable/","photos":[]},{"tags":[{"name":"mongodb","slug":"mongodb","permalink":"https://codermino.github.io/tags/mongodb/"}],"title":"mongodb操作","date":"2020/01/12","text":"查询 find(): db.集合名称.find(&#123;条件文档&#125;) findOne(): db.集合名称.findOne(&#123;条件文档&#125;) pretty():将结果格式化 db.集合名称.find(&#123;条件文档&#125;).pretty() 查询条件 等于:默认是等于判断，没有运算符 小于: $lt (less than) 小于等于:$lte (less than equal) 大于: $gt (greater than) 大于等于:$gte (greater than equal) 不等于: $ne (not equal) eq: db.集合名称.find(&#123;条件文档:&#123;查询条件&#125;&#125;) 使用\"$in\",\"$nin\"判断是否在某个范围内 eq: 查询年龄为18、28的学生 db.stu.find(&#123;age:&#123;$in:[18,28]&#125;&#125;) and: 在json中写多个条件即可 查询年龄大于或等于18，并且性别为true的学术 db.stu.find(age:&#123;$gte:18&#125;,gender:true) or: 使用$or,值为数组，数组中每个元素为json 查询年龄大于18，或性别为false的学生 db.stu.find(&#123;$or:[&#123;age:&#123;$gt:18&#125;&#125;,&#123;gender:false&#125;]&#125;) 查询年龄大于18或者性别为男生，并且姓名是Mark db.stu.find(&#123;$or:[&#123;age:&#123;$gt:18&#125;&#125;,&#123;gender:false&#125;],name:'Mark'&#125;) 正则 使用//或$regex编写正则表达式 查询姓李的学生 db.stu.find(&#123;last_name:/^李/&#125;) db.stu.find(&#123;last_name:&#123;$regex:'^李'&#125;&#125;) limit和skip limit():用于等去指定数量的文档 db.集合名称.find().limit(NUMBER) 查询2条学生信息 db.stu.find().limit(2) skip():用于跳过指定数量的文档 db.集合名称.find().skip(NUMBER) db.stu.find().skip(2) 同时使用 db.stu.find().limit(3).skip(2) 或 db.stu.find().skip(3).limit(2) ★ 自定义查询 在mongodb中支持js语法 使用$where后面写一个函数，返回满足条件的数据 查询年龄大于20的学生 db.stu.find(&#123; $where:function()&#123; return this.age&gt;20; &#125; &#125;) 投影 在查询到的返回结果中，只选择必要的字段 db.集合名称.find(&#123;&#125;,&#123;字段名称:1,.....&#125;) 参数为字段与值，值为1表示显示，值为0不显示 特殊：对于_id列默认是显示的，如果不显示需要明确设置为0 eq: db.stu.find(&#123;&#125;,&#123;_id:0,name:1,age:1,gender:1&#125;) 排序 方法sort(),用于对集合进行排序 db.集合名称.find().sort(&#123;字段1,...&#125;) 参数1位升序排列 参数-1为降序排列 根据性别降序，再根据年龄升序 eq: db.stu.find().sort(&#123;gender:-1,age:1&#125;) 统计个数 方法count()用于统计结果集中文档条数 db.集合名称.find(&#123;条件&#125;).count() db.集合名称.count(&#123;条件&#125;) db.stu.find(&#123;gender:true&#125;).count() db.stu.count(&#123;age:&#123;$gt:20&#125;&#125;,gender:true) 消除重复 方法distinct()对数据进行去重 db.集合名称.distinct('去重字段',&#123;条件&#125;) db.stu.distinct('address',&#123;age:&#123;$gt:20&#125;&#125;) 数据备份和恢复 备份的语法： mongoddump -h host -d dbname -o dbdirectory -h：服务器地址，也可以指定端口号 -d：需要备份的数据库名称 -o：备份的数据存放的位置，此目录中存放着备份出来的数据 eq: mongodump -h 地址 -d test -o 路径 如何备份的是本地的服务器，那么-h可以省略不写 恢复语法： mongorestore -g dbhost -d dbname --dir dbdirectory -h：服务器地址 -d：需要恢复的数据库实例 --dir：备份数据所在的位置 eq: mongoretore -h 地址 -d test2 --dir 地址/test 聚合 聚合(aggregate)是基于数据处理的聚合管道，每个文档通过一个由多个阶段(stage) 组成的管道，可以对每个极端的管道进行分组、过滤等功能，然后经过一系列的处理， 输出相应的结果。 db.集合名称.aggregate(&#123;管道:&#123;表达式&#125;&#125;) 常用管道 在mongodb中，文档处理完毕后，通过管道进行下一次处理 常用管道如下： $group：将集合中的文档分组，可用于统计结果 $match：过滤数据，只输出符合条件的文档 $project：修改输入文档的结构，如重命名、增加、删除字段、创建计算结果 $sort：将输入文档排序后输出 $limit：限制聚合管道返回的文档树 $skip：跳过指定数量的文档，并返回余下的文档 $unwind：将数组类型的字段进行拆分 常用管道表达式 $sum：计算总和，$sum:1表示以一倍计数 $avg：计算平均值 $min：获取最小值 $max：获取最大值 $psuh：在结果文档中插入值到一个数组中 $first：根据资源文档的排序获取第一个文档数据 $last：根据资源文档的排序获取最后一个文档数据 分组 将集合中的文档分组，可用于统计结果 _id表示分组的依据，使用某个字段的格式为'$字段' eq:统计男生、女生的总人数 db.stu.aggregate(&#123; $group: &#123; _id:'$gender', counter:&#123;$sum:1&#125; &#125; &#125;) Group by null 将集合中所有文档分为一组 eq:求学生总人数、平均年靓 db.stu.aggregate(&#123; $group: &#123; _id:null, counter:&#123;$sum:1&#125;, avgAge:&#123;$avg:'$age'&#125; &#125; &#125;) 处理$project 修改输入文档的结构，如重命名、增加、删除字段、创建计算结果 eq1:查询学生的姓名、年龄 db.stu.aggregate( &#123;$project:&#123;_id:0,name:1,age:1&#125;&#125; ) eq2:查询男生、女生人数，输出个数 db.stu.aggregate( &#123;$group:&#123;_id:'$gender',counter:&#123;$sum:1&#125;&#125;&#125;, &#123;$project:&#123;_id:0,counter:1&#125;&#125; ) 综合实例 选择年龄大于20的学生，观察男性和女性有多少人 db.stu.aggregate( &#123;$match:&#123;age:&#123;$gt:20&#125;&#125;&#125;, &#123;$group:&#123;_id:\"$gender\",count:&#123;$sum:1&#125;&#125;&#125;, &#123;$project:&#123;_id:0,gender:\"$_id\",count:1&#125;&#125; ) 排序 $sort -将输入文档排序后输出 eq1: -查询学生信息，按照年龄升序排序 b.stu.aggregate(&#123;$sort:&#123;age:1&#125;&#125;) eq2: -查询男生、女生人数。按人数降序排序 db.stu.aggregate( &#123;$group:&#123;_id:'$gender',counter:&#123;$sum:1&#125;&#125;&#125;, &#123;$sort:&#123;counter:-1&#125;&#125; ) limit和skip $limit -限制聚合管道返回的文数 -eq -查询2条学生信息 db.stu.aggregate(&#123;$limit:2&#125;) $skip -跳过指定数量的文档，并返回余下的文档 -eq -查询从第3条开始的学生信息 db.stu.aggregate(&#123;$skip:2&#125;) -eq 统计男生、女生人数，按人数升序,取第二条数据 db.stu.aggregate( &#123;$group:&#123;_id:'$gender',counter:&#123;$sum:1&#125;&#125;&#125; &#123;$sort:&#123;counter:1&#125;&#125;, &#123;$skip:1&#125;, &#123;$limit:1&#125; ) tip: -注意顺序：先写skip，再写limit（这样做效率更高） -如果想要_id不显示出来，那么在$group中加上_id:null unwind $unwind -属性值为false表示丢弃属性值为空的文档 -属性preserveNullAndEmptyArrays值为true表示保留属性值为空的文档 用法： db.invertory.aggregate(&#123; $unwind:&#123; path:'$字段名称', preserveNullAndEmptyArrays:&lt;boolean&gt;#防止数据丢失 &#125; &#125;) 索引 索引：以提升查询速度 测试：插入10万条数据到数据库中 for(i=0;i&lt;100000;i++)&#123; db.t255.insert(&#123;name:'test'+i,age:i&#125;) &#125; db.t1.find(&#123;name:'test10000'&#125;) db.t1.find(&#123;name:'test10000'&#125;).explain('executionStats') 建立索引之后的对比： 语法：db.集合.ensureIndex(&#123;属性：1&#125;)，1表示升序，-1表示降序 具体操作：db.t255.ensureIndex(&#123;name:1&#125;) db.t1.find(&#123;name:'test10000'&#125;).explain('executionStats') 在默认情况下索引字段的值可以相同 创建唯一索引（索引的值是唯一的）： -db.t1.ensureIndex(&#123;'name':1&#125;,&#123;'unique':true&#125;) 建立联合索引（什么时候需要联合索引）： -db.t1.ensureIndex(&#123;name:1,age:1&#125;) 查看当前集合的所有索引: -db.t1.getIndexes() 删除索引： -db.t1.dropIndex(&#123;'索引名称':1&#125;) mongodb mysql redis的区别和使用场景 -mysql是关系型数据库，支持事务 -MongoDB，redis非关系型数据库，不支持事务 -mysql，mongodb,redis的使用根据如何方便进行选择 -希望速度快的时候，选择mongodb或者是redis -数据量过大的时候，选择频繁使用的数据存入redis，其他的存入mongodb -mongodb不用提前建表建数据库，使用方便，字段数量不确定的时候使用mongodb -后续需要用到数据之间的关系，此时考虑mysql 爬虫数据去重 使用数据库建立关键字段（一个或者多个）建立索引进行去重 根据url地址进行去重 -使用场景： url地址对应的数据不会变的情况，url地址能够唯一判别一条数据的情况 -思路 url存在redis中 拿到url地址，判断url在redis的url的集合中是否存在 存在： 说明url已经被请求过，不再请求 不存在： url地址没有被请求过，请求，把该url存入redis的集合中 -布隆过滤器 使用多个加密算法加密url地址，得到多个值 往对应值的位置把结果设置为1 新来一个url地址，一样通过加密算法生成多个值 如果对应的位置的值全为1，说明这个url地址已经抓取过 否则没有抓过，就把对应位置的值设置为1 根据数据本身进行去重 选择特定的字段，使用加密算法（md5,sha1）将字段进行加密，生成字符串，存入redis的集合中 后续新来一条数据，同样的方法进行加密，如果得到的字符串在redis中存在，说明数据存在，对数据进行更新，否则说明数据不存在，直接插入","permalink":"https://codermino.github.io/2020/01/12/mongodb%E6%93%8D%E4%BD%9C/","photos":[]},{"tags":[{"name":"git","slug":"git","permalink":"https://codermino.github.io/tags/git/"}],"title":"Git基本操作","date":"2019/12/05","text":"master:默认开发分支 Head :默认开发分支 origin:默认远程版本库 Head^ :Head 的父提交 创建版本库 git clone &lt;url&gt; 克隆远程版本库 git init 初始化本地版本库 修改和提交 git status 查看状态 git diff 查看变更内容 git add . 跟踪所有改动过的文件#跟踪指定的文件 git add &lt;file&gt; 跟踪指定的文件 git mv &lt;old&gt; &lt;new&gt; 文件改名 git rm &lt;file&gt; 删除文件 git rm --cached &lt;file&gt; 停止跟踪文件但不删除 git commit -m 'message' 提交所有更新过的文件 git commit --amend 修改最后一次提交 查看提交历史 git log 查看提交历史 git log -p &lt;file&gt; 查看指定文件的提交历史 git blame &lt;file&gt; 以列表方式查看指定文件的提交历史 撤销 git reset --hard HEAD 撤消工作目录中所有未提交文件的修改内容 git checkout HEAD &lt;file&gt; 撤消指定的未提交文件的修改内容 git revert &lt;commit&gt; 撤消指定的提交 分支与标签 git branch 显示所有本地分支 git checkout &lt;branch/tag&gt; 切换到指定分支或标签 git branch &lt;new- branch&gt; 创建新分支 git branch -d &lt;branch&gt; 删除本地分支 git tag 列出所有本地标签 git tag &lt;tagname&gt; 基于最新提交创建标签 git tag -d &lt;tagname&gt; 删除标签 合并与衍合 git merge &lt;branch&gt; 合并指定分支到当前分支 git rebase &lt;branch&gt; 行合指定分支到当前分支 远程操作 git remote -V 查看远程版本库信息 git remote show &lt;remote&gt; 查看指定远程版本库信息 git remote add &lt;remote&gt; &lt;url&gt; 添加远程版本库 git fetch &lt;remote&gt; 从远程库获取代码 git pull &lt;remote&gt; &lt;branch&gt; 下载代码及快速合并 git push &lt;remote&gt; &lt;branch&gt; 上传代码及快速合并 git push &lt;remote&gt; : &lt;branch/ tag一name&gt; 删除远程分支或标签 git push --tags 上传所有标签 例子 git 新建分支并提交本地代码到远程分支 step1：在本地新建分支 git branch newbranch step2：把本地分支push到远程 git push origin newbranch step3：切换到该分支 git checkout newbranch step4：查看本地修改 git status step5：添加本地修改 git add . step6：commit修改 git commit -m 'XXXX' step7：push代码 git push OVER 在github远程端删除一个分支 git push origin :newbranch (分支名前的冒号代表删除)","permalink":"https://codermino.github.io/2019/12/05/Git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/","photos":[]}]}